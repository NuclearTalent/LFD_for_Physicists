{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e86122e",
   "metadata": {},
   "source": [
    "# Solutions\n",
    "\n",
    "Here are answers and solutions to selected exercises.\n",
    "\n",
    "```{solution} exercise:StochasticProcess:first-example\n",
    ":label: solution:StochasticProcess:first-example\n",
    ":class: dropdown\n",
    "\n",
    "- The initial variable is from a uniform distribution: $p_{X_0}(x_0) = \\mathcal{U}\\left( [0,1] \\right)$.\n",
    "- Variable $X_n$ is obtained from\n",
    "$p_{X_n \\vert X_0, X_1, \\ldots, X_{n-1}} \\left( x_n | x_0, x_1, \\ldots, x_{n-1} \\right) = \\mathcal{U}\\left( [0,1] \\right) + \\sum_{i=0}^{n-1} x_i$\n",
    "```\n",
    "\n",
    "````{solution} exercise:conditional-probabilities-stochastic-process\n",
    ":label: solution:conditional-probabilities-stochastic-process\n",
    ":class: dropdown\n",
    "\n",
    "The histograms on the diagonal show the distributions $\\p{X_n}$ which are marginalized over $X_{n−1}, \\ldots, X_0$. The off-diagonal plots show the joint distributions $\\p{X_i,X_j}$ which are marginalized over $X_{n−1}, \\ldots, X_0$ with $n=\\max(i,j)$ and excluding $X_{\\min(i,j)}$. Note that these are distributions of random variables $X_n$, not random values $x_n$.\n",
    "\n",
    "More explicitly:\n",
    "\n",
    "* $\\p{X_0}$ has no correlated random variables marginalized out since it starts the sequence.\n",
    "* $\\p{X_1}$ is marginalized over $X_0$.\n",
    "* $\\p{X_2}$ is marginalized over $X_1,X_0$.\n",
    "* $\\p{X_3}$ is marginalized over $X_2,X_1,X_0$.\n",
    "* $\\p{X_0,X_1}$ has no correlated random variables marginalized out.\n",
    "* $\\p{X_1,X_2}$ is marginalized over $X_0$.\n",
    "* $\\p{X_2,X_3}$ is marginalized over $X_0, X_1$.\n",
    "* $\\p{X_1,X_3}$ is marginalized over $X_0, X_2$.\n",
    "* $\\p{X_0,X_3}$ is marginalized over $X_1, X_2$.\n",
    "* $\\p{X_0,X_2}$ is marginalized over $X_1, X_3$.\n",
    "\n",
    "The dependence of $X_3$ on $X_0$ is not directly observed since $\\pdf{X_3}{X_0}$ is not shown. However, from Eq. {eq}`eq:Statistics:conditional-probability` we have that $\\pdf{X_3}{X_0} = \\p{X_0,X_3} / \\p{X_0}$. And since $\\p{X_0}$ is uniform, we find that $\\pdf{X_3}{X_0} \\neq \\p{X_3}$.\n",
    "In other words, $X_3$ \"remembers\" $X_0$.\n",
    "````\n",
    "\n",
    "````{solution} exercise:construct-stochastic-process\n",
    ":label: solution:construct-stochastic-process\n",
    ":class: dropdown\n",
    "\n",
    "Here's one possible solution. It is a slightly more general random walk.\n",
    "\n",
    "```{code-block} python\n",
    "class exerciseSP(SP):\n",
    "    def start(self,random_state):\n",
    "        return random_state.uniform()\n",
    "\n",
    "    def update(self, random_state, history):\n",
    "    \treturn history[-1] + random_state.uniform())\n",
    "```\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%========================\n",
    "% Extra exercises not yet coordinated with the text.\n",
    "%========================\n",
    "%--```{exercise}\n",
    "%--:label: exercise:the-poisson-process-1\n",
    "%--\n",
    "%--This exercise will explore the important Poisson distribution in\n",
    "%--more detail and illustrate how the Poisson distribution can arise from a \n",
    "%--stochastic proccess.\n",
    "%--\n",
    "%--Define a stochastic process $\\{X_i : i \\in \\{1,2,\\dots\\}\\}$ where $X_i \\sim \n",
    "%--\\mathrm{exp}(\\lambda)$ and independent. This means that the pdf is \n",
    "%--\n",
    "%--$$f_{X_i}(x) = \\begin{cases} \\lambda e^{-\\lambda x},\n",
    "%--\\quad x \\geq 0, \\\\ 0, \\quad x < 0. \\end{cases}\n",
    "%--$$\n",
    "%--\n",
    "%--This stochatic process is quite trivial, sice it is just an i.i.d sequence of random variables being exponentially \n",
    "%--distributed.\n",
    "%--\n",
    "%--From this process define a new process $\\{T_n : n \\in \\{1,2,\\dots\\}\\}$ where\n",
    "%--$T_n = \\sum_{i=1}^n X_i$.\n",
    "%--\n",
    "%--(i) Show that $\\{T_n : n\\in\\{1,2,\\dots\\}\\}$ is a Markov Process.\n",
    "%--\n",
    "%--(ii) Calculate the distribution function (cdf) of $T_n$, i.e. \n",
    "%--$F_{T_n} (t) = P(T_n \\leq t)$ to show that $T_n \\sim \\Gamma(\\lambda,n)$ \n",
    "%--\n",
    "%--*Hint*: This is most easily shown by indction. (1.) Show that a exponential \n",
    "%--distribution is a special case of the $\\Gamma$ distribution (2.) Consider \n",
    "%--the distribution of $Z = T_{n-1} + X_n$ where you assume that $T_{n-1}$ has a \n",
    "%--$\\Gamma$--distribution.\n",
    "%--\n",
    "%--(iii) (optional) Try implementing this stochastic process in the Python class.\n",
    "%--\n",
    "%--\n",
    "%--(iv) Define a random variable $N(t) =$ max$\\{n : T_n \\leq t \\}$.\n",
    "%--Show that $N(t) \\sim \\mathrm{Poisson}(\\lambda t)$.\n",
    "%--\n",
    "%--*Hint*: First show that $N(t)\\geq j$ if and only if  $T_j \\leq t$. Use this to express \n",
    "%--$P(N(t) = j)$ in terms of the distribution function you calculated earlier.\n",
    "%--\n",
    "%--\n",
    "%--```\n",
    "%--```{exercise}\n",
    "%--:label: exercise:the-poisson-process-2\n",
    "%--This exercise will illustrate another situation where the Poisson distribution \n",
    "%--shows up.\n",
    "%--\n",
    "%--Consiser a physics experiment where you want to measure some process that emitts \n",
    "%--some kind of particle in different directions. The goal is to infer the probability\n",
    "%--distribution that the particles follow. Consider that the detector is a screen\n",
    "%--with some length, $L$, which is divided up in $K$ bins. The number of particels \n",
    "%--detected in each bin will approach the underlying probability distribution after \n",
    "%--long enough time, but for a finite number of samples it may look somethig like the\n",
    "%--figure below. The red curv is the underlying pdf that we want to know, and the blue\n",
    "%--histogram shown the outcome of the experiment.\n",
    "%--\n",
    "%--![file](./figs/prob_fig.png)\n",
    "%--\n",
    "%--We will study the distribution of the number of particles in each bin, and how\n",
    "%--that is affected by the number of particales that are detected, $N$, and the setup \n",
    "%--of the experiment. This distribution is important to be able to cunstruct the \n",
    "%--likelihood of the observed data given some model to describe the process.\n",
    "%--\n",
    "%--Suppuse that $N_i, \\ i=1,\\dots,K$ is the number of particles detected in the \n",
    "%--experiment in the corresponding bins. Let's focus on bin $i=1$.\n",
    "%--\n",
    "%--(*i*) Show that if all the particles can be considered independent the probability\n",
    "%--of observing $N_i$ particles in bin $i=1$ is following a Binomial distribution. \n",
    "%--Assume that the variation of the underlying pdf can be considered constant \n",
    "%--in each bin, meaning that the widths of the bins are very small.\n",
    "%--\n",
    "%--*Hint*: Use that the random variable $N_i$ is a sum of Bernoulli distributed \n",
    "%--random variables.\n",
    "%--\n",
    "%--(*ii*) Compute the *generating function* for the Binomial distribution and \n",
    "%--the Poisson distribution.\n",
    "%--\n",
    "%--*Hint*: Remember that the generating function for a discrete random varaiable, $X$,\n",
    "%--is defined as\n",
    "%--\n",
    "%--$$\n",
    "%--G(s) =  \\mathbb{E}\\left(s^{X}\\right) = \\sum_n s^n \\cdot f_X(n).\n",
    "%--$$\n",
    "%--\n",
    "%--For the calculation of the generating function for the binomial distribution\n",
    "%--you can use the fact that the binomial distribution is a sum of independent \n",
    "%--random variables with a generating function that is easier to compute.\n",
    "%--\n",
    "%--(*iii*) Prove the so-called Poisson Limit Theorem, that the binomial\n",
    "%--distribution approaches the Poisson distribution in the limit \n",
    "%--\n",
    "%--$$\n",
    "%--N \\to \\infty, \\quad N p_i \\to \\lambda. \n",
    "%--$$\n",
    "%--\n",
    "%--where $\\lambda$ is a finite constant, i.e. \n",
    "%--\n",
    "%--$$\n",
    "%--P(N_i = n_i) \\to_{N\\to\\infty} \\frac{\\lambda^{n_i}}{n_i!}e^{-\\lambda}\n",
    "%--$$\n",
    "%--\n",
    "%--*Hint*: Use the definition of $e$ and explicitly construct a sequence of decreasing \n",
    "%--probabilities $p_i \\to_{N\\to\\infty} 0$ that fulfills the constraint above.\n",
    "%--\n",
    "%--(*iv*) Use scipy-stats to compare the binomial distribution and the Poisson distribution\n",
    "%--and verify that the statement you just prove makes sense. Vary the size of \n",
    "%--$\\lambda = p_i N \\in \\{0.5,2,10\\}$ for large $N \\sim 1000$. What do you observe? \n",
    "%--How can you explain it?\n",
    "%--\n",
    "%--```\n",
    "%========================\n",
    "% Solutions to extra exercises.\n",
    "%========================\n",
    "%--```{solution} exercise:the-poisson-process-1\n",
    "%--:label: solution:the-poisson-process-1\n",
    "%--:class: dropdown\n",
    "%--\n",
    "%--(*i*)\n",
    "%--- Want to show that\n",
    "%--\n",
    "%--$$\n",
    "%--P(T_n = t_n | T_{n-1} = t_{n-1}, \n",
    "%--\\dots, T_1 = t_1) = P(T_n=t_n| T_{n-1} = t_{n-1}).\n",
    "%--$$\n",
    "%--\n",
    "%--\\begin{align}\n",
    "%--P(T_n = t_n | T_{n-1} = t_{n-1}, \n",
    "%--\\dots, T_1 = t_1) =\\\\= P(X_n + T_{n-1} = t_n | T_{n-1} = t_{n-1}, \n",
    "%--\\dots, T_1 = t_1) =\\\\= P(X_n = t_n - t_{n-1}| T_{n-1} = t_{n-1}, \n",
    "%--\\dots, T_1 = t_1)\n",
    "%--\\end{align}\n",
    "%--\n",
    "%--- Multiply and divide by $P(X_{n} | T_n)$ and show by independence that\n",
    "%--all the remaining factors cancel and you are left with\n",
    "%--\n",
    "%--\\begin{align}\n",
    "%--P(T_n = t_n | T_{n-1} = t_{n-1}, \n",
    "%--\\dots, T_1 = t_1) =\\\\ = P(X_n=t_n - t_{n-1} | T_{n-1} = t_{n-1}) = \n",
    "%--P(T_n=t_n| T_{n-1} = t_{n-1})\n",
    "%--\\end{align}\n",
    "%--\n",
    "%--which shows that it is a Markov process.\n",
    "%--\n",
    "%--(*ii*)\n",
    "%--\n",
    "%--- Use the hint.\n",
    "%--\n",
    "%--(*iii*)\n",
    "%--\n",
    "%--- We follow the hints.\n",
    "%--- Assume that $N(t) \\geq j$. Since $N(t)$ is the maximum $n$ for whith $T_n \\leq t$\n",
    "%--we get that $T_j \\leq t$. Assume that $T_j \\leq t$. This means that the maximum \n",
    "%--$n$ for which $T_n \\leq t$ hold must be larger of equal to $j$, hence $N(t) \\leq j$.\n",
    "%--- The probability $P(N(t) = j)$ can be expressed as\n",
    "%--\n",
    "%--$$\n",
    "%--P(N(t) = j) = P(N(t)\\geq j) - P(N(t)\\geq j+1).\n",
    "%--$$\n",
    "%--\n",
    "%--By the above equality we can express these probabilities as\n",
    "%--\n",
    "%--$$\n",
    "%--P(N(t) = j) = P(T_j \\leq t) - P(T_{j+1} \\leq t) = F_{T_j}(t) - F_{T_{j+1}}(t) = \n",
    "%--\\frac{(\\lambda t )^j}{j!} e^{-\\lambda t}.\n",
    "%--$$\n",
    "%--\n",
    "%--```\n",
    "%--\n",
    "%--\n",
    "%--```{solution} exercise:the-poisson-process-2\n",
    "%--:label: solution:the-poisson-process-2\n",
    "%--:class: dropdown\n",
    "%--\n",
    "%--(*i*)\n",
    "%--- We use the hint and assume that the probability of hitting bin $i$ is $p_i$.\n",
    "%--This means that each particle is hitting this bin with probability $p_i$ and\n",
    "%--missing with probability $1-p_i$. This experiment is repeated $N$ times. This means \n",
    "%--that\n",
    "%--\n",
    "%--$$\n",
    "%--N_i = \\sum_{k=1}^N B_k,  \n",
    "%--$$\n",
    "%--where $B_k \\sim$ Bernoulli$(p_i)$ and independent. This means that the probability\n",
    "%--of $n_i$ hits among $N$ can be obtained from the Binomial theorem \n",
    "%--\n",
    "%--$$\n",
    "%--P(N_i = n_i) = \\left(\\frac{N}{n_i}\\right) p_i^{n_i}(1-p_i)^{N-n_i}.\n",
    "%--$$\n",
    "%--\n",
    "%--(*ii*)\n",
    "%--\n",
    "%--- Use the definition of the generating function to obtain for the Poisson\n",
    "%--distribution\n",
    "%--\n",
    "%--$$\n",
    "%--G_P(s) = \\sum_k s^k \\frac{\\lambda^k}{k!} e^{-\\lambda} = e^{\\lambda(s-1)}\n",
    "%--$$\n",
    "%--\n",
    "%--- For the Binomial distribution we use the property of the generating functions\n",
    "%--that $G_{Bin}(s) = \\left(G_{Bern}(s)\\right)^N$, which holds by independence.\n",
    "%--\n",
    "%--$$\n",
    "%--G_{Bin}(s) = \\left( (ps) + (1-p)\\right)^N\n",
    "%--$$\n",
    "%--\n",
    "%--(*iii*)\n",
    "%--- We will prove this by proving that the generating function for the binomial \n",
    "%--distribution approaches the generating function for the Poisson distribution in\n",
    "%--the $N\\to \\infty$ limit. We drope the $i$ index from now on.\n",
    "%--\n",
    "%--- Using the hint an explicit secuence is for example $p_N = \\frac{\\lambda}{N} + \n",
    "%--o\\left(\\frac{1}{N}\\right)$ (The small $o$ notation means that $N^m o(1/N^m)\n",
    "%--\\to_{N\\to\\infty} 0$) \n",
    "%--\n",
    "%--- Looking at the generating function for the Binomial distribution we have\n",
    "%--\n",
    "%--$$\n",
    "%--(ps + (1-p))^N = (1+p_N(s-1))^N = \\exp{\\left[N \\ln\\left( 1 +\\frac{\\lambda}{N} + \n",
    "%--o\\left(\\frac{1}{N}\\right)\\right)\\left(s-1\\right)\\right]}\n",
    "%--$$\n",
    "%--\n",
    "%--Taylor expanding the logarithm and takning the limit gives\n",
    "%--\n",
    "%--$$\n",
    "%--\\exp\\left[N\\left(p_N(s-1) + o\\left(\\frac{1}{N}\\right)\\right)\\right] \n",
    "%--\\to_{N\\to\\infty} \\exp\\left[\\lambda(s-1)\\right]\n",
    "%--$$\n",
    "%--\n",
    "%--```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   11
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}