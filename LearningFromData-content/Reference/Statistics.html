
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>35. Statistics concepts and notation &#8212; Combined Learning from Data materials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/coloredpages.css?v=0a037ad7" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=6bd7df4c" />
    <link rel="stylesheet" type="text/css" href="../../_static/myadmonitions.css?v=89ac28d1" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"loader": {"load": ["[tex]/textmacros"]}, "chtml": {"mtextInheritFont": true}, "tex": {"packages": {"[+]": ["textmacros"]}, "macros": {"data": "\\mathcal{D}", "pars": "\\boldsymbol{\\theta}", "para": "\\theta", "optpars": "\\pars^*", "optpara": "\\para^*", "prob": "\\mathbb{P}", "cprob": ["\\prob\\left( #1 \\, \\left\\vert \\, #2 \\right. \\right)", 2], "cprobsub": ["\\prob_{#1}\\left( #2 \\, \\left\\vert \\, #3 \\right. \\right)", 3], "pdf": ["p \\left( #1 \\, \\left\\vert \\, #2 \\right. \\right)", 2], "pdfsub": ["p_{#1} \\left( #2 \\, \\left\\vert \\, #3 \\right. \\right)", 3], "p": ["p \\left( #1 \\right)", 1], "psub": ["p_{#1} \\left( #2 \\right)", 2], "futuredata": "\\mathcal{F}", "expect": ["\\mathbb{E} \\left[ #1 \\right]", 1], "var": ["\\text{Var} \\left( #1 \\right)", 1], "std": ["\\text{Std} \\left( #1 \\right)", 1], "cov": ["\\text{Cov} \\left( #1, #2 \\right)", 2], "dmat": "\\boldsymbol{X}", "models": ["\\boldsymbol{M}\\left( #1 \\, ; \\, #2 \\right)", 2], "model": ["M\\left( #1 \\, ; \\, #2 \\right)", 2], "modeloutputs": "\\boldsymbol{M}", "modeloutput": "M", "MLmodel": ["\\boldsymbol{\\hat{y}}\\left( #1 \\right)", 1], "MLoutputs": "\\boldsymbol{\\hat{y}}", "MLoutput": "\\hat{y}", "outputs": "\\boldsymbol{y}", "inputs": "\\boldsymbol{x}", "targets": "\\boldsymbol{t}", "weights": "\\boldsymbol{w}", "testoutputs": "\\boldsymbol{y}^\\odot", "testinputs": "\\boldsymbol{x}^\\odot", "output": "y", "inputt": "x", "target": "t", "weight": "w", "testoutput": "y^\\odot", "MLtestoutput": "\\hat{y}^\\odot", "testinput": "x^\\odot", "trainingdata": "\\mathcal{T}", "LaTeX": "\\text{LaTeX}", "residual": "\\epsilon", "residuals": "\\boldsymbol{\\epsilon}", "zeros": "\\boldsymbol{0}", "covres": "\\boldsymbol{\\Sigma_{\\epsilon}}", "covpars": "\\boldsymbol{\\Sigma_{\\pars}}", "tildecovpars": "\\boldsymbol{\\widetilde{\\Sigma}_{\\pars}}", "sigmas": "\\boldsymbol{\\sigma}", "sigmai": "\\sigma_i", "sigmares": "\\sigma_{\\epsilon}", "cbar": "\\bar c", "Lra": "\\Longrightarrow", "yth": "y_{\\text{th}}", "yexp": "y_{\\text{exp}}", "ym": "y_{\\text{m}}", "thetavec": "\\boldsymbol{\\theta}", "parsLR": "\\boldsymbol{\\beta}", "paraLR": "\\beta", "covparsLR": "\\boldsymbol{\\Sigma_{\\parsLR}}", "optparsLR": "\\parsLR^*", "optparaLR": "\\paraLR^*", "tildecovparsLR": "\\boldsymbol{\\widetilde{\\Sigma}_{\\parsLR}}", "alphavec": "\\boldsymbol{\\alpha}", "muvec": "\\boldsymbol{\\mu}", "phivec": "\\boldsymbol{\\phi}", "betavec": "\\boldsymbol{\\beta}", "sigmavec": "\\boldsymbol{\\sigma}", "Sigmavec": "\\boldsymbol{\\Sigma}", "thetavechat": "\\widehat\\thetavec", "avec": "\\boldsymbol{a}", "Bvec": "\\boldsymbol{B}", "fvec": "\\boldsymbol{f}", "mvec": "\\boldsymbol{m}", "qvec": "\\boldsymbol{q}", "rvec": "\\boldsymbol{r}", "uvec": "\\boldsymbol{u}", "wvec": "\\boldsymbol{w}", "xvec": "\\boldsymbol{x}", "yvec": "\\boldsymbol{y}", "wt": "\\widetilde", "nb": "n_b", "mel": ["\\langle #1 | #2 | #3 \\rangle", 3], "qoi": "\\mathbf{Q}", "ytrue": "y_{\\text{true}}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'LearningFromData-content/Reference/Statistics';</script>
    <script src="../../_static/custom.js?v=33f35b7a"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="36. Gradient-descent optimization" href="../ModelingOptimization/GradientDescent.html" />
    <link rel="prev" title="34. Guide to Jupyter Book markdown" href="../Backmatter/JB_tests.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../Intro/About.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo-copilot.png" class="logo__image only-light" alt="Combined Learning from Data materials - Home"/>
    <script>document.write(`<img src="../../_static/logo-copilot.png" class="logo__image only-dark" alt="Combined Learning from Data materials - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../Intro/About.html">
                    Learning from data for physicists:
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Intro/Invitation.html">1. Invitation to inductive inference</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Intro/Introduction.html">2. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction/sec-01-physicist-s-perspective.html">2.1. Physicistâ€™s perspective</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction/sec-02-bayesian-workflow.html">2.2. Bayesian workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction/sec-03-machine-learning.html">2.3. Machine learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction/sec-04-virtues.html">2.4. Virtues</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part I: Bayesian methods for scientific modeling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/RootBayesianBasics.html">3. Overview of Part I</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs.html">4. Inference and PDFs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements.html">4.1. Statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as.html">4.2. Manipulating probabilities: Bayesian rules of probability as principles of logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions.html">4.3. Probability density functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary.html">4.4. Looking ahead</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/MoreBayesTheorem.html">4.5. Review of Bayesâ€™ theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/DataModelsPredictions.html">4.6. Data, models, and predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Bayesian_epistemology.html">4.7. *Aside: Bayesian epistemology</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Posteriors.html">5. Bayesian posteriors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Exploring_pdfs.html">5.1. ðŸ“¥ Exploring PDFs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Exploring_pdfs_followups.html">Follow-ups to Exploring PDFs</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Visualizing_correlated_gaussians.html">5.2. ðŸ“¥ Visualizing correlated Gaussian distributions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Gaussians.html">5.3. Gaussians: A couple of frequentist connections</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/visualization_of_CLT.html">ðŸ“¥ Visualization of the Central Limit Theorem</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors.html">5.4. Interpreting 2D posteriors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/chi_squared_tests.html">5.5. ðŸ“¥ Demonstration: Sum of normal variables squared</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing.html">6. Updating via Bayes' rule</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians.html">6.1. Coin tossing: Frequentists and Bayesaians</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter.html">6.2. When do priors matter? When donâ€™t they matter?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically.html">6.3. Computing the posterior analytically</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm.html">6.4. Degree of belief/credibility intervals vs frequentist 1-sigma intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping.html">6.5. Take-aways and follow-up questions from coin flipping</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/demo-BayesianBasics.html">6.6. ðŸ“¥ Demonstration:  Bayesian Coin Tossing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive.html">6.7. ðŸ“¥ Demonstration: Coin tossing (with widget)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation.html">7. Error propagation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation/sec-01-error-propagation-i-nuisance-parameters-and-marginalization.html">7.1. Error propagation (I): Nuisance parameters and marginalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation/sec-02-error-propagation-ii-changing-variables.html">7.2. Error propagation (II): Changing variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation/sec-03-error-propagation-iii-a-useful-approximation.html">7.3. Error propagation (III): A useful approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation/sec-04-solutions.html">7.4. Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/UsingBayes.html">8. Bayes in practice</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/BayesianAdvantages.html">8.1. Advantages of the Bayesian approach</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianWorkflow/BayesianWorkflow.html">8.2. Bayesian research workflow</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf.html">8.3. Bayesian Linear Regression (BLR)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../ModelingOptimization/demo-ModelValidation.html">ðŸ“¥ Demonstration: Linear Regression and Model Validation</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/Exercises_parameter_estimation.html">9. Exercises for Part I</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/exercise_sum_product_rule.html">9.1. Exercise: Checking the sum and product rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes.html">9.2. Exercise: Standard medical example using Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise.html">9.3. ðŸ“¥ Parameter estimation I: Gaussian mean and variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise.html">9.4. ðŸ“¥ Radioactive lighthouse problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background.html">9.5. ðŸ“¥ Amplitude of a signal in the presence of background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I.html">9.6. ðŸ“¥ Parameter estimation example: fitting a straight line</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II.html">9.7. ðŸ“¥ Parameter estimation example: fitting a straight line II</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part II: Advanced Bayesian methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../BayesianStatistics/RootAdvancedMethods.html">10. Overview of Part II</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../OtherTopics/DiscrepancyModels.html">11. Discrepancy Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/DiscrepancyModels/sec-01-koh-and-boh-discrepancy-models.html">11.1. KOH and BOH discrepancy models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/DiscrepancyModels/sec-02-framework.html">11.2. Framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/DiscrepancyModels/sec-03-the-ball-drop-model.html">11.3. The ball-drop model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/MD_balldrop_v1.html">11.4. ðŸ“¥ Ball-drop experiment notebook</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/Assigning.html">12. Assigning probabilities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/IgnorancePDF.html">12.1. Assigning probabilities (I): Indifferences and translation groups</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/demo-straight_lines.html">Alternative notebook with MCMC sampling</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/MaxEnt2.html">12.2. Assigning probabilities (II): The principle of maximum entropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction.html">12.3. ðŸ“¥ Maximum Entropy for reconstructing a function from its moments</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers.html">13. ðŸ“¥ Dealing with outliers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../BayesianStatistics/ComputationalBayes/BayesLinear.html">14. Bayes goes linear: History matching</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/Multimodel_inference.html">15. Multi-model inference with Bayes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/ModelSelection/ModelSelection.html">15.1. Model Selection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients.html">Evidence calculation for EFT expansions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/ModelSelection/BUQ/two_model_evidence.html">Follow-up to EFT evidence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/ModelSelection/BUQ/computing_evidence.html">Computing the evidence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus.html">Demo: Multimodal distributions with two samplers</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/ModelMixing/model_mixing.html">15.2. Model averaging and mixing </a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part III: MCMC sampling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../StochasticProcesses/RootMCMC.html">16. Overview of Part III</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../StochasticProcesses/StochasticProcesses.html">17. Stochastic processes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/Metropolis_Poisson_example.html">17.7. Metropolis-Hasting MCMC sampling of a Poisson distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/demo-MCMC.html">17.8. Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/Recap_BUQ.html">17.9. Recap of Poisson and more about MCMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2.html">17.10. Parameter estimation example: Gaussian noise and averages II</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/MCMC-random-walk-and-sampling.html">17.11. Exercise: Random walk</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../StochasticProcesses/MCMC_overview.html">18. Overview of Markov Chain Monte Carlo</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/MarkovChains.html">18.1. Markov chains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/MCMC.html">18.2. Markov chain Monte Carlo sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/MCMC_intro_BUQ.html">18.3. Alternative MCMC introduction (Gregory)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse.html">18.4. Assignment: 2D radioactive lighthouse location using MCMC</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../StochasticProcesses/Advanced_MCMC.html">19. Advanced MCMC</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/ComputationalBayes/AdvancedMCMC.html">19.1. Advanced Markov chain Monte Carlo sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/MCMC-diagnostics.html">19.2. Overview: MCMC Diagnostics</a></li>

<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/intuition_sampling.html">19.4. Intuition on sampling and best practices</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../StochasticProcesses/Other_samplers.html">20. HMC and other samplers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../StochasticProcesses/BUQ2/HMC_intro_BUQ.html">20.1. Hamiltonian Monte Carlo (HMC) overview and visualization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../StochasticProcesses/BUQ2/Liouville_theorem_visualization.html">Liouville Theorem Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms.html">Solving orbital equations with different algorithms</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/zeus.html">20.2. The Zeus Ensemble Slice Sampler</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../StochasticProcesses/BUQ2/PyMC_intro_updated.html">20.3. PyMC Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../StochasticProcesses/OverviewIntroPyMC.html">Overview of Intro to PyMC notebook</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers.html">20.4. Comparing samplers for a simple problem</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part IV: Machine learning: A Bayesian perspective</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../MachineLearning/RootML.html">21. Overview of Part IV</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/GP/RootGP.html">22. Overview of Gaussian processes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../MachineLearning/GP/GaussianProcesses.html">22.4. Introduction to Gaussian processes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/CF/demo-GaussianProcesses.html">ðŸ“¥ demo-GaussianProcesses notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/lecture_20.html">GP recap; GP applications; (old lecture 20)</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../MachineLearning/GP/Sklearn_demos.html">22.5. scikit-learn demo notebooks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/plot_gpr_noisy_targets.html">ðŸ“¥ One-dimension regression example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/plot_gpr_prior_posterior.html">ðŸ“¥ Prior and posterior with different kernels</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../MachineLearning/GP/GPy_demos.html">22.6. GPy demo notebooks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/demo-GaussianProcesses.html">Gaussian processes demonstration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/CF/exercise_GP_GPy.html">Exercise: Gaussian processes using <code class="docutils literal notranslate"><span class="pre">GPy</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/Gaussian_processes_exercises.html">Exercise: Gaussian Process models with GPy</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/LogReg/LogReg.html">23. Logistic Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/MachineLearningExamples.html">23.5. Machine Learning: First Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet.html">23.6. Exercise: Logistic Regression and neural networks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/ANN/MachineLearning.html">24. Machine learning: Overview and notation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/NeuralNet.html">24.5. Artifical neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/NeuralNet/demo-NeuralNet.html">24.6. Demonstration: Neural network classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch.html">24.7. ðŸ“¥ ANN from ChatGPT using PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/ModelValidation.html">24.8. Model validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/DataBiasFairness.html">24.9. Data bias and fairness in machine learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/NeuralNet/NeuralNetBackProp.html">24.10. *Neural networks: Backpropagation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../OtherTopics/ANNFT.html">25. ANNs in the large-width limit (ANNFT)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/random_initialized_ANN_vs_width.html">25.3. ðŸ“¥ Distributions of Randomly-Initialized ANNs</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/BNN/bnn.html">26. Bayesian neural nets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/BNN/demo-bnn.html">26.4. Demonstration: Variational Inference and Bayesian Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/BNN/exercises_BNN.html">26.5. Exercise: Bayesian neural networks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/CNN/cnn.html">27. *Convolutional neural nets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/CNN/demo-cnn.html">27.6. Demonstration: Image recognition with Convolutional Neural Networks</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part V: Other topics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../OtherTopics/RootOtherTopics.html">28. Overview of Part V </a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../OtherTopics/Emulators.html">29. Emulators</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/ComputationalBayes/BayesFast.html">29.1. Bayes goes fast: Emulators (from CF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/ComputationalBayes/extra_RBM_emulators.html">29.2. RBM emulators (BUQ)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../OtherTopics/Student_t_distribution_from_Gaussians.html">30. ðŸ“¥ Student t distribution from Gaussians</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../OtherTopics/SVD.html">31. PCA, SVD, and all that</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/linear_algebra_games_including_SVD.html">31.5. ðŸ“¥ demo-SVD notebook</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../OtherTopics/qbism.html">32. QBism: Bayesian quantum mechanics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Backmatter</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Backmatter/bibliography.html">33. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Backmatter/JB_tests.html">34. Guide to Jupyter Book markdown</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix A: Reference</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">35. Statistics concepts and notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ModelingOptimization/GradientDescent.html">36. Gradient-descent optimization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix B: Scientific modeling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ModelingOptimization/RootScientificModeling.html">37. Overview of scientific modeling material</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ModelingOptimization/OverviewModeling.html">38. Overview of modeling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-01-notation.html">38.1. Notation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-02-models-in-science.html">38.2. Models in science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-03-parametric-versus-non-parametric-models.html">38.3. Parametric versus non-parametric models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-04-linear-versus-non-linear-models.html">38.4. Linear versus non-linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-05-regression-analysis-optimization-versus-inference.html">38.5. Regression analysis: optimization versus inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-06-exercises.html">38.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-07-solutions.html">38.7. Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ModelingOptimization/LinearModels.html">39. Linear models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-01-definition-of-linear-models.html">39.1. Definition of linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-02-regression-analysis-with-linear-models.html">39.2. Regression analysis with linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-03-ordinary-linear-regression-warmup.html">39.3. Ordinary linear regression: warmup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-04-ordinary-linear-regression-in-practice.html">39.4. Ordinary linear regression in practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-05-solutions.html">39.5. Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ModelingOptimization/MathematicalOptimization.html">40. Mathematical optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/MathematicalOptimization/sec-01-gradient-descent-optimization.html">40.1. Gradient-descent optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/MathematicalOptimization/sec-02-batch-stochastic-and-mini-batch-gradient-descent.html">40.2. Batch, stochastic and mini-batch gradient descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/MathematicalOptimization/sec-03-adaptive-gradient-descent-algorithms.html">40.3. Adaptive gradient descent algorithms</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix C: Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Setup/RootGettingStarted.html">41. Overview of Getting started material</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Setup/exercise_Intro_01_Jupyter_Python.html">42. ðŸ“¥ Exercise: Jupyter notebooks and Python</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Setup/more_python_and_jupyter.html">43. More about Python and Jupyter notebooks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Setup/exercise_Intro_02_Jupyter_Python.html">43.4. ðŸ“¥ Python lists and iterations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Setup/exercise_Intro_03_Numpy.html">43.5. ðŸ“¥ Linear algebra operations with NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Setup/demo-Intro.html">43.6. ðŸ“¥ Reading data and fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Setup/Simple_widgets_v1.html">43.7. ðŸ“¥ Making a simple widget-based UI</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Setup/setting_up.html">44. Setting up for using this Jupyter Book</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Setup/installing_anaconda.html">44.1. Using Anaconda</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Setup/using_github.html">44.2. Using GitHub</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">TALENT mini-projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/RootMiniProjects.html">Overview of mini-projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/mini-project_I_toy_model_of_EFT.html">ðŸ“¥ MP I: Parameter estimation for a toy model of an EFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/model-selection_mini-project-IIa.html">ðŸ“¥ MP IIa: Model selection basics</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee.html">ðŸ“¥ MP IIb: How many lines?</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Mini-projects/Mini-project_IIb_overview.html">Overview of Mini-project IIb: How many lines?</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/mini-project_IIIa_bayesian_optimization.html">ðŸ“¥ MP IIIa: Bayesian optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo.html">ðŸ“¥ MP IIIb: Bayesian Neural Networks</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/NuclearTalent/LFD_for_Physicists/main?urlpath=tree/./LearningFromData-content/Reference/Statistics.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/NuclearTalent/LFD_for_Physicists" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/NuclearTalent/LFD_for_Physicists/issues/new?title=Issue%20on%20page%20%2FLearningFromData-content/Reference/Statistics.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/LearningFromData-content/Reference/Statistics.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="../../_sources/LearningFromData-content/Reference/Statistics.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Statistics concepts and notation</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notation">35.1. Notation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#important-definitions">35.2. Important definitions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-probability-measure">The probability measure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-variables-probability-distribution-and-density">Random variables: probability distribution and density</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-values-and-moments">Expectation values and moments</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#central-moments-variance-and-covariance">Central moments: Variance and Covariance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#important-distributions">35.3. Important distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-uniform-distribution">The uniform distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-distribution">Gaussian distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-gaussian-distribution">Multivariate Gaussian distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-introduction-to-scipy-stats">35.4. Quick introduction to  <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-example">Code example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pseudo-random-number-generator">(Pseudo) random number generator</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#point-estimates-and-credible-regions">35.5. Point estimates and credible regions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-median-mode">Mean, median, mode</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#credible-regions">Credible regions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-probability">35.6. Types of probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">35.7. Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions">35.8. Solutions</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="statistics-concepts-and-notation">
<span id="sec-statistics"></span><h1><span class="section-number">35. </span>Statistics concepts and notation<a class="headerlink" href="#statistics-concepts-and-notation" title="Link to this heading">#</a></h1>
<blockquote class="epigraph">
<div><blockquote>
<div><p>â€œIf your result needs a statistician then you should design a better experiment.â€</p>
</div></blockquote>
<p class="attribution">â€”Ernest Rutherford</p>
</div></blockquote>
<section id="notation">
<span id="sec-statistics-notation"></span><h2><span class="section-number">35.1. </span>Notation<a class="headerlink" href="#notation" title="Link to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Quantity</p></th>
<th class="head text-center"><p>General notation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>Conditional probability</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\cprob{A}{B}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Covariance</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\cov{X}{Y}\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Distribution function</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(P(x)\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Empty set</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\emptyset\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Event</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(A\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Expectation value</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\expect{X}\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Likelihood function</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\mathcal{L}(\para)\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Model parameters</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\para\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Probability density function</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\p{x}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Probability mass function</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\p{x}\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Probability measure</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\prob\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Random variable</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(X\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Sample space</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(S\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Standard deviation</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\std{X}\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Variance</p></td>
<td class="text-center"><p><span class="math notranslate nohighlight">\(\var{X}\)</span></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="important-definitions">
<h2><span class="section-number">35.2. </span>Important definitions<a class="headerlink" href="#important-definitions" title="Link to this heading">#</a></h2>
<p>The set of all possible outcomes of an experiment is known as the sample space and is here denoted by <span class="math notranslate nohighlight">\(S\)</span>. We can think of events <span class="math notranslate nohighlight">\(A\)</span> as subsets of the sample space.</p>
<p>Whenever <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are events that we are interested in, then we can also reasonably concern ourselves with the events (<span class="math notranslate nohighlight">\(A \cap B\)</span>), (<span class="math notranslate nohighlight">\(A \cup B\)</span>), and (<span class="math notranslate nohighlight">\(\bar{A}\)</span>) which correspond to (<span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span>), (<span class="math notranslate nohighlight">\(A\)</span> or <span class="math notranslate nohighlight">\(B\)</span>), and (not <span class="math notranslate nohighlight">\(A\)</span>), respectively.</p>
<section id="the-probability-measure">
<span id="introduction-definitions"></span><h3>The probability measure<a class="headerlink" href="#the-probability-measure" title="Link to this heading">#</a></h3>
<div class="proof definition admonition" id="definition:probability-measure">
<p class="admonition-title"><span class="caption-number">Definition 35.1 </span> (Probability measure)</p>
<section class="definition-content" id="proof-content">
<p>A probability measure is a function <span class="math notranslate nohighlight">\(\prob : A \to [0,1]\)</span> satisfying</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\prob (S)=1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\prob (\emptyset)=0\)</span></p></li>
<li><p>If <span class="math notranslate nohighlight">\(A_1, A_2, \ldots A_n\)</span> is a collection of disjoint events, such that <span class="math notranslate nohighlight">\(A_i \cap A_j = \emptyset\)</span> for all <span class="math notranslate nohighlight">\(i \neq j\)</span>, then
<span class="math notranslate nohighlight">\(\prob \left( \cup_{i=1}^n A_i \right) = \sum_{i=1}^n \prob (A_i)\)</span>.</p></li>
</ul>
</section>
</div><p>In particular, we will often consider the probability for two events to be true <span class="math notranslate nohighlight">\(\prob (A \cap B)\)</span>. For brevity, we will often use the simpler notation <span class="math notranslate nohighlight">\(\prob (A, B)\)</span>.</p>
<div class="proof definition admonition" id="definition:independent-events">
<p class="admonition-title"><span class="caption-number">Definition 35.2 </span> (Independent events)</p>
<section class="definition-content" id="proof-content">
<p>Two events <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are independent if</p>
<div class="amsmath math notranslate nohighlight" id="equation-a4ea56ff-89d4-4bd6-aa3d-f78852c1a6bf">
<span class="eqno">(35.1)<a class="headerlink" href="#equation-a4ea56ff-89d4-4bd6-aa3d-f78852c1a6bf" title="Permalink to this equation">#</a></span>\[\begin{equation}
  \prob (A, B) = \prob (A)\prob (B)
\end{equation}\]</div>
</section>
</div><div class="proof definition admonition" id="definition:conditional-probability">
<p class="admonition-title"><span class="caption-number">Definition 35.3 </span> (Conditional probability)</p>
<section class="definition-content" id="proof-content">
<p>Given <span class="math notranslate nohighlight">\(\prob (A) &gt; 0\)</span> we define the conditional probability of <span class="math notranslate nohighlight">\(B\)</span> given <span class="math notranslate nohighlight">\(A\)</span> as</p>
<div class="math notranslate nohighlight" id="equation-eq-statistics-conditional-probability">
<span class="eqno">(35.2)<a class="headerlink" href="#equation-eq-statistics-conditional-probability" title="Link to this equation">#</a></span>\[
  \cprob{B}{A} = \frac{\prob (A, B)}{\prob (A)}.
\]</div>
<p>Alternatively this can be expressed via the <strong>product rule</strong> of probability theory</p>
<div class="math notranslate nohighlight" id="equation-eq-statistics-product-rule">
<span class="eqno">(35.3)<a class="headerlink" href="#equation-eq-statistics-product-rule" title="Link to this equation">#</a></span>\[
\prob (A, B) = \cprob{B}{A} \prob (A).
\]</div>
</section>
</div><p>Given <span class="math notranslate nohighlight">\(\prob (A) &gt; 0\)</span> we have that <span class="math notranslate nohighlight">\(A\)</span> and <span class="math notranslate nohighlight">\(B\)</span> are independent if and only if <span class="math notranslate nohighlight">\(\cprob{B}{A} = \prob (B)\)</span>.</p>
<p>The <strong>total law of probability</strong> can be obtained from the disjoint-union property of <a class="reference internal" href="#definition:probability-measure">Definition 35.1</a> and the product rule <a class="reference internal" href="#equation-eq-statistics-product-rule">(35.3)</a>. Consider a partition <span class="math notranslate nohighlight">\(B_1, B_2, \ldots, B_n\)</span> of the complete state space (meaning that <span class="math notranslate nohighlight">\(B_i \cap B_j = \emptyset\)</span> for all <span class="math notranslate nohighlight">\(i \neq j\)</span> and <span class="math notranslate nohighlight">\(\sum_{i=1}^n \prob (B_i) = 1\)</span>) such that <span class="math notranslate nohighlight">\(\prob (B_i) &gt; 0\)</span> for all <span class="math notranslate nohighlight">\(i\)</span>. Then</p>
<div class="math notranslate nohighlight" id="equation-eq-statistics-discrete-total-probability">
<span class="eqno">(35.4)<a class="headerlink" href="#equation-eq-statistics-discrete-total-probability" title="Link to this equation">#</a></span>\[
\prob (A) = \sum_{i=1}^n \cprob{A}{B_i} \prob (B_i) = \sum_{i=1}^n \prob (A, B_i). 
\]</div>
<p>This process of summing over all possible states of an event in a joint probability to obtain the <strong>marginal</strong> probability of the other event is known as marginalization.</p>
<p>A simple example of this law would be the statement</p>
<blockquote>
<div><p>The total probability that it rains tomorrow is the sum of the probability that it rains tomorrow and that it rains today plus the probability that it rains tomorrow and not today.</p>
</div></blockquote>
<p>Each of those joint probabilities can be factorized according to the product rule. For example, the probability that it rains tomorrow and that it rains today is the conditional probability of raining tomorrow given that it rains today times the probability that it rains today.</p>
<p>The point here is that the total probability of rain tomorrow is the sum of those two terms since the two events â€œit rains todayâ€ and â€œit does not rain todayâ€ form a complete and exhaustive partition of outcomes of the experiment â€œwill it rain today?â€.</p>
</section>
<section id="random-variables-probability-distribution-and-density">
<h3>Random variables: probability distribution and density<a class="headerlink" href="#random-variables-probability-distribution-and-density" title="Link to this heading">#</a></h3>
<p>Let us introduce the concept of random variables and use those to introduce probability distribution and density functions.</p>
<div class="proof definition admonition" id="definition:random-variable">
<p class="admonition-title"><span class="caption-number">Definition 35.4 </span> (Random variable and distribution function)</p>
<section class="definition-content" id="proof-content">
<p>A random (or stochastic) variable is a function <span class="math notranslate nohighlight">\(X: S \to \mathbb{R}\)</span>.</p>
<p>The <strong>distribution function</strong> <span class="math notranslate nohighlight">\(P\)</span> for a random variable <span class="math notranslate nohighlight">\(X\)</span> is the function <span class="math notranslate nohighlight">\(P : \mathbb{R} \to [0,1]\)</span>, given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-5aec8850-b2c3-4059-90d1-29fc98140a50">
<span class="eqno">(35.5)<a class="headerlink" href="#equation-5aec8850-b2c3-4059-90d1-29fc98140a50" title="Permalink to this equation">#</a></span>\[\begin{equation}
    P(x) = \prob (X \leq x).
\end{equation}\]</div>
<p>We can write <span class="math notranslate nohighlight">\(P_X(x)\)</span> where it is necessary to emphasize the role of <span class="math notranslate nohighlight">\(X\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="definition:joint-probability-distribution">
<p class="admonition-title"><span class="caption-number">Definition 35.5 </span> (Joint probability distribution)</p>
<section class="definition-content" id="proof-content">
<p>The joint distribution function of a vector <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> of random variables <span class="math notranslate nohighlight">\(\boldsymbol{X} = (X_1, X_2, \ldots, X_n)\)</span> is the function <span class="math notranslate nohighlight">\(P : \mathbb{R}^n \to [0,1]\)</span> given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-fd3cefc6-8692-4519-8b7a-1d88d0d42946">
<span class="eqno">(35.6)<a class="headerlink" href="#equation-fd3cefc6-8692-4519-8b7a-1d88d0d42946" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(\boldsymbol{x}) = \prob (\boldsymbol{X} \leq \boldsymbol{x}), \qquad x \in \mathbb{R}^n. 
\end{equation}\]</div>
<p>We can write <span class="math notranslate nohighlight">\(P_{\boldsymbol{X}}\)</span> where it is necessary to emphasize the role of <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span>.</p>
</section>
</div><p>For random variables that are continuous it will be very useful to work with probability densities. Let us define those, starting however with the corresponding quantity (probability mass) for discrete random variables.</p>
<div class="proof definition admonition" id="definition:probability-mass-function">
<p class="admonition-title"><span class="caption-number">Definition 35.6 </span> (Probability mass function)</p>
<section class="definition-content" id="proof-content">
<p>The random variable <span class="math notranslate nohighlight">\(X\)</span> is called <strong>discrete</strong> if it takes values only in some countable subset <span class="math notranslate nohighlight">\(\{ x_1, x_2, \ldots\}\)</span> of <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>. The function <span class="math notranslate nohighlight">\(p : \mathbb{R} \to [0,1]\)</span>, given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-8fd27de5-e1fd-4493-a5e7-e0caa82e9e15">
<span class="eqno">(35.7)<a class="headerlink" href="#equation-8fd27de5-e1fd-4493-a5e7-e0caa82e9e15" title="Permalink to this equation">#</a></span>\[\begin{equation}
    p(x) = \prob (X = x),
\end{equation}\]</div>
<p>is known as its <strong>probability mass function</strong>. Again, we can write <span class="math notranslate nohighlight">\(p_X(x)\)</span> where it is necessary to emphasize the role of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>The <strong>joint probability mass function</strong> of a random vector <span class="math notranslate nohighlight">\(\boldsymbol{X} = (X_1, X_2, \ldots, X_n)\)</span> is the function <span class="math notranslate nohighlight">\(p : \mathbb{R}^n \to [0,1]\)</span> given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-654824c4-2149-409a-9ba6-d3a5824c3f38">
<span class="eqno">(35.8)<a class="headerlink" href="#equation-654824c4-2149-409a-9ba6-d3a5824c3f38" title="Permalink to this equation">#</a></span>\[\begin{equation}
p(x_1, x_2, \ldots, x_n) = \prob (X_1=x_1, X_2=x_2, \ldots, X_n=x_n). 
\end{equation}\]</div>
</section>
</div><div class="proof definition admonition" id="definition:probability-density-function">
<p class="admonition-title"><span class="caption-number">Definition 35.7 </span> (Probability density function)</p>
<section class="definition-content" id="proof-content">
<p>The random variable <span class="math notranslate nohighlight">\(X\)</span> is called <strong>continuous</strong> if its distribution function can be expressed as</p>
<div class="amsmath math notranslate nohighlight" id="equation-018e8075-16a8-47c1-b40b-cd3ad8784aab">
<span class="eqno">(35.9)<a class="headerlink" href="#equation-018e8075-16a8-47c1-b40b-cd3ad8784aab" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(x) = \int_{-\infty}^x p(z) dz, \qquad x \in \mathbb{R}, 
\end{equation}\]</div>
<p>for some integrable function <span class="math notranslate nohighlight">\(p : \mathbb{R} \to [0,\infty)\)</span> called the <strong>probability density function</strong> (PDF). Again, we can write <span class="math notranslate nohighlight">\(p_X(x)\)</span> where it is necessary to emphasize the role of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>The <strong>joint probability density function</strong> of a random vector <span class="math notranslate nohighlight">\(\boldsymbol{X} = (X_1, \ldots, X_n)\)</span> of continuous variables is the function <span class="math notranslate nohighlight">\(p : \mathbb{R}^n \to [0,\infty)\)</span> given by</p>
<div class="amsmath math notranslate nohighlight" id="equation-4c3645cf-1147-4d1a-ad59-191452096fa8">
<span class="eqno">(35.10)<a class="headerlink" href="#equation-4c3645cf-1147-4d1a-ad59-191452096fa8" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(x_1, \ldots, x_n) = \int_{u_1=-\infty}^{x_1} \ldots \int_{u_n=-\infty}^{x_n} p(u_1, \ldots, u_n) du_1, \ldots, du_n. 
\end{equation}\]</div>
</section>
</div><p>Note that we will not differentiate in notation between probability mass and density functions as the context should make it clear whether it describes the probability density of a discrete or continuous variable. We will also refer to both as a PDF.</p>
<p>While discrete examples tend to be simpler, situations with continuous variables are more common in physics.</p>
<p>Following the above definition, there are some properties that all PDFs must have. Here we list some important ones using the simplest example of a single (continuous) random variable <span class="math notranslate nohighlight">\(X\)</span></p>
<ol class="arabic">
<li><p>The first one is positivity</p>
<div class="amsmath math notranslate nohighlight" id="equation-d55546d1-841f-447b-ab1c-da7663a29a8d">
<span class="eqno">(35.11)<a class="headerlink" href="#equation-d55546d1-841f-447b-ab1c-da7663a29a8d" title="Permalink to this equation">#</a></span>\[\begin{equation}
 0 \leq p(x).
 \end{equation}\]</div>
<p>Naturally, it would be nonsensical for any of the values of the domain to occur with a probability density less than <span class="math notranslate nohighlight">\(0\)</span>.</p>
</li>
<li><p>Also, the PDF must be normalized. That is, all the probabilities must add up
to one.  The probability of <em>anything</em> to happen is always unity. For a continuous PDF this condition is</p>
<div class="amsmath math notranslate nohighlight" id="equation-5e333fa6-66f2-4d14-b521-9704b07b71d5">
<span class="eqno">(35.12)<a class="headerlink" href="#equation-5e333fa6-66f2-4d14-b521-9704b07b71d5" title="Permalink to this equation">#</a></span>\[\begin{equation}
 \int_{-\infty}^\infty p(x)\,dx =  1.
\end{equation}\]</div>
<p>The corresponding condition for a discrete PDF is <span class="math notranslate nohighlight">\(\sum_{i} p(x_i) =  1\)</span>.</p>
</li>
<li><p>The probability for <em>any</em> specific outcome <span class="math notranslate nohighlight">\(x\)</span> of a continuous variable <span class="math notranslate nohighlight">\(X\)</span> is zero</p>
<div class="amsmath math notranslate nohighlight" id="equation-2fc952fd-ea19-47c2-81e1-2d067a0642cb">
<span class="eqno">(35.13)<a class="headerlink" href="#equation-2fc952fd-ea19-47c2-81e1-2d067a0642cb" title="Permalink to this equation">#</a></span>\[\begin{equation}
 \prob (X=x) =  0, \qquad \text{for all } x \in \mathbb{R},
\end{equation}\]</div>
<p>since probabilities will be computable from the integral measure <span class="math notranslate nohighlight">\(p(x) dx\)</span> and <span class="math notranslate nohighlight">\(\prob (X=x)\)</span> would correspond to <span class="math notranslate nohighlight">\(dx \to 0\)</span>.</p>
</li>
<li><p>Instead it makes more sense to discuss the probability for the outcome being within a domain. E.g., for the univariate case we can quantify</p>
<div class="amsmath math notranslate nohighlight" id="equation-face0ca7-3534-492b-b70d-8e39b83c1878">
<span class="eqno">(35.14)<a class="headerlink" href="#equation-face0ca7-3534-492b-b70d-8e39b83c1878" title="Permalink to this equation">#</a></span>\[\begin{equation}
 \prob (a \leq X \leq b) =  \int_a^b p(x) dx. 
\end{equation}\]</div>
<p>From which we can also note that PDFs are not dimensionless objects. We must have <span class="math notranslate nohighlight">\([p(x)] = [x]^{-1}\)</span> for the integral to produce a dimensionless probability.</p>
</li>
</ol>
<p>These properties can be generalized to the multivariate case <span class="math notranslate nohighlight">\(p(x_1, x_2, \ldots)\)</span>.</p>
<p>For the multivariate case we also introduce the important concepts of <strong>marginalization</strong> and <strong>independence</strong> .</p>
<div class="proof property admonition" id="property:marginal-density-functions">
<p class="admonition-title"><span class="caption-number">Property 35.1 </span> (Marginal density functions)</p>
<section class="property-content" id="proof-content">
<p>Given a joint density function <span class="math notranslate nohighlight">\(p(x,y)\)</span> of two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>, the (marginal) probability density function of <span class="math notranslate nohighlight">\(X\)</span> is obtained via marginalization</p>
<div class="amsmath math notranslate nohighlight" id="equation-25320882-af56-4062-88a6-c667bb6a571e">
<span class="eqno">(35.15)<a class="headerlink" href="#equation-25320882-af56-4062-88a6-c667bb6a571e" title="Permalink to this equation">#</a></span>\[\begin{equation}
p(x) = \int_{-\infty}^\infty p(x,y) dy,
\end{equation}\]</div>
<p>and vice versa for <span class="math notranslate nohighlight">\(p(y)\)</span>.</p>
</section>
</div><p>Marginalization is a very powerful technique as it allows to extract probabilites for a variable of interest when dealing with multivariate problems.</p>
<div class="proof property admonition" id="property:independence">
<p class="admonition-title"><span class="caption-number">Property 35.2 </span> (Independence)</p>
<section class="property-content" id="proof-content">
<p>Two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are independent if (and only if) the joint density function factorizes</p>
<div class="math notranslate nohighlight" id="equation-eq-statistics-independence">
<span class="eqno">(35.16)<a class="headerlink" href="#equation-eq-statistics-independence" title="Link to this equation">#</a></span>\[
p(x,y) = p(x) p(y).
\]</div>
</section>
</div><p>Suppose that <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> have the joint distribution function <span class="math notranslate nohighlight">\(p(x,y)\)</span>. We wish to discuss the conditional probability distribution of <span class="math notranslate nohighlight">\(Y\)</span> given that <span class="math notranslate nohighlight">\(X\)</span> takes the value <span class="math notranslate nohighlight">\(x\)</span>. However, we need to be careful since the event <span class="math notranslate nohighlight">\(X=x\)</span> has zero probability. Instead, we can consider the event <span class="math notranslate nohighlight">\(x \leq X \leq x+dx\)</span> which leads to the following definition</p>
<div class="proof definition admonition" id="definition:conditional-probability-distribution">
<p class="admonition-title"><span class="caption-number">Definition 35.8 </span> (Conditional probability-distribution)</p>
<section class="definition-content" id="proof-content">
<p>The conditional distribution function of <span class="math notranslate nohighlight">\(Y\)</span> given <span class="math notranslate nohighlight">\(X=x\)</span> is</p>
<div class="amsmath math notranslate nohighlight" id="equation-b7ff07d8-ad85-4463-8d2b-9e54a2a6d7fc">
<span class="eqno">(35.17)<a class="headerlink" href="#equation-b7ff07d8-ad85-4463-8d2b-9e54a2a6d7fc" title="Permalink to this equation">#</a></span>\[\begin{equation}
  P_{Y \vert X}(y \vert x) = \int_{-\infty}^y \frac{p(x,y')}{p_X(x)} dy'
\end{equation}\]</div>
<p>for any <span class="math notranslate nohighlight">\(x\)</span> such that <span class="math notranslate nohighlight">\(p_X(x) &gt; 0\)</span>.</p>
</section>
</div><p>The integrand is then defined as the conditional PDF</p>
<div class="amsmath math notranslate nohighlight" id="equation-c357e2d4-546c-4660-ae12-873e8fcce575">
<span class="eqno">(35.18)<a class="headerlink" href="#equation-c357e2d4-546c-4660-ae12-873e8fcce575" title="Permalink to this equation">#</a></span>\[\begin{equation}
p_{Y \vert X}(y \vert x) = \frac{p(x,y)}{p_X(x)} = \frac{p(x,y)}{\int_{-\infty}^{\infty} p(x,y) dy},
\end{equation}\]</div>
<p>for any <span class="math notranslate nohighlight">\(x\)</span> such that <span class="math notranslate nohighlight">\(p_X(x)&gt;0\)</span>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Probability densities are usually introduced in the context of random variables (as we did here). However, from the Bayesian viewpoint, probabilities are used more generally to describe our state of knowledge. This means, for example, that we will use probability densities to quantify our knowledge of physics model parameters. Such a PDF would not make sense in an approach that requires randomness in considered variables.</p>
</div>
</section>
<section id="expectation-values-and-moments">
<span id="sec-expectationvaluesandmoments"></span><h3>Expectation values and moments<a class="headerlink" href="#expectation-values-and-moments" title="Link to this heading">#</a></h3>
<div class="proof definition admonition" id="definition:expectation-value">
<p class="admonition-title"><span class="caption-number">Definition 35.9 </span> (Expectation value)</p>
<section class="definition-content" id="proof-content">
<p>Let <span class="math notranslate nohighlight">\(h(x)\)</span> be an arbitrary continuous function on the domain <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> of the continuous, random
variable <span class="math notranslate nohighlight">\(X\)</span> whose PDF is <span class="math notranslate nohighlight">\(p(x)\)</span>. We define the <em>expectation value</em>
of <span class="math notranslate nohighlight">\(h\)</span> with respect to <span class="math notranslate nohighlight">\(p\)</span> as follows</p>
<div class="amsmath math notranslate nohighlight" id="equation-a6e6740a-7f0d-478d-90d4-505bc2b76871">
<span class="eqno">(35.19)<a class="headerlink" href="#equation-a6e6740a-7f0d-478d-90d4-505bc2b76871" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathbb{E}_p[h] = \int_{-\infty}^\infty \! h(x)p(x)\,dx .
\end{equation}\]</div>
<p>The corresponding definition for a discrete variable <span class="math notranslate nohighlight">\(X\)</span> is</p>
<div class="amsmath math notranslate nohighlight" id="equation-e89fb2d0-5ddc-4183-94a4-4330ffd93318">
<span class="eqno">(35.20)<a class="headerlink" href="#equation-e89fb2d0-5ddc-4183-94a4-4330ffd93318" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathbb{E}_p[h] =  \sum_{i}\! h(x_i)p(x_i) .
\end{equation}\]</div>
</section>
</div><p>Note that we usually drop the index <span class="math notranslate nohighlight">\(p\)</span> and just write <span class="math notranslate nohighlight">\(\mathbb{E}[h]\)</span>.</p>
<p>A particularly useful class of expectation values are the <strong>moments</strong>. The <span class="math notranslate nohighlight">\(n\)</span>-th moment of the PDF <span class="math notranslate nohighlight">\(p(x)\)</span> is defined as follows</p>
<div class="amsmath math notranslate nohighlight" id="equation-e947699d-ade5-417a-9770-7b312dd0d12c">
<span class="eqno">(35.21)<a class="headerlink" href="#equation-e947699d-ade5-417a-9770-7b312dd0d12c" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathbb{E}[X^n] = \int_{-\infty}^\infty \! x^n p(x)\,dx
\end{equation}\]</div>
<p>The zero-th moment <span class="math notranslate nohighlight">\(\mathbb{E}[1]\)</span> is just the normalization condition of
<span class="math notranslate nohighlight">\(p\)</span>. The first moment, <span class="math notranslate nohighlight">\(\mathbb{E}[X]\)</span>, is called the <strong>mean</strong> of <span class="math notranslate nohighlight">\(p\)</span>
and is often denoted by the greek letter <span class="math notranslate nohighlight">\(\mu\)</span></p>
<div class="math notranslate nohighlight" id="equation-eq-statistics-mean">
<span class="eqno">(35.22)<a class="headerlink" href="#equation-eq-statistics-mean" title="Link to this equation">#</a></span>\[
\mathbb{E}[X] \equiv \mu \equiv \int_{-\infty}^\infty x p(x)dx,
\]</div>
<p>for a continuous distribution and</p>
<div class="amsmath math notranslate nohighlight" id="equation-e474cae5-a180-4701-9801-84bddb735730">
<span class="eqno">(35.23)<a class="headerlink" href="#equation-e474cae5-a180-4701-9801-84bddb735730" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathbb{E}[X] \equiv \mu \equiv \sum_{i} x_i p(x_i),
\end{equation}\]</div>
<p>for a discrete distribution.</p>
<p>Qualitatively it represents the average value of the
PDF and is therefore sometimes called the expectation value of <span class="math notranslate nohighlight">\(p(x)\)</span>.</p>
</section>
<section id="central-moments-variance-and-covariance">
<span id="sec-centralmoments"></span><h3>Central moments: Variance and Covariance<a class="headerlink" href="#central-moments-variance-and-covariance" title="Link to this heading">#</a></h3>
<p>Another special case of expectation values is the set of <strong>central moments</strong>, with the <span class="math notranslate nohighlight">\(n\)</span>-th central moment defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-3472af81-4fef-41bf-b143-cd36db236de3">
<span class="eqno">(35.24)<a class="headerlink" href="#equation-3472af81-4fef-41bf-b143-cd36db236de3" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathbb{E}\left[ \left( X - \mathbb{E}[X] \right)^n \right] = \int_{-\infty}^\infty \! \left( x-\mathbb{E}[X] \right)^n p(x)\,dx .
\end{equation}\]</div>
<p>The zero-th and first central moments are both trivial; equal to <span class="math notranslate nohighlight">\(1\)</span> and
<span class="math notranslate nohighlight">\(0\)</span>, respectively. Instead, the second central moment is of particular interest.</p>
<div class="proof definition admonition" id="definition:variance">
<p class="admonition-title"><span class="caption-number">Definition 35.10 </span> (Variance)</p>
<section class="definition-content" id="proof-content">
<p>The <strong>variance</strong>  of a random variable <span class="math notranslate nohighlight">\(X\)</span> is usually denoted <span class="math notranslate nohighlight">\(\sigma^2\)</span> or Var<span class="math notranslate nohighlight">\((X)\)</span> and is defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-42e54bba-0386-435b-aebd-4fd22646271e">
<span class="eqno">(35.25)<a class="headerlink" href="#equation-42e54bba-0386-435b-aebd-4fd22646271e" title="Permalink to this equation">#</a></span>\[\begin{equation}
\text{Var}(X) \equiv \sigma^2  \equiv \mathbb{E}\left[ \left( X - \mathbb{E}[X] \right)^2 \right]
\end{equation}\]</div>
</section>
</div><p>We note that</p>
<div class="amsmath math notranslate nohighlight" id="equation-15026dba-4548-4434-806f-ef484e8d4329">
<span class="eqno">(35.26)<a class="headerlink" href="#equation-15026dba-4548-4434-806f-ef484e8d4329" title="Permalink to this equation">#</a></span>\[\begin{align}
\sigma^2 &amp;= \int_{-\infty}^\infty (x-\mathbb{E}[X] )^2 p(x)dx\\
&amp;=  \int_{-\infty}^\infty \left(x^2 - 2 x \mathbb{E}[X] +\mathbb{E}[X]^2\right)p(x)dx \\
&amp; =  \mathbb{E}[X^2]  - 2 \mathbb{E}[X] \mathbb{E}[X]  + \mathbb{E}[X]^2 \\
&amp;=  \mathbb{E}[X^2]  - \mathbb{E}[X]^2
\end{align}\]</div>
<p>The positive square root of the variance, <span class="math notranslate nohighlight">\(\sigma = +\sqrt{\sigma^2}\)</span> is called the
<strong>standard deviation</strong> of <span class="math notranslate nohighlight">\(p\)</span>. It is the root-mean-square (RMS)
value of the deviation of the PDF from its mean value, interpreted
qualitatively as the â€œspreadâ€ of <span class="math notranslate nohighlight">\(X\)</span> around its mean.</p>
<p>When dealing with two random variables it is useful to introduce the <strong>covariance</strong></p>
<div class="proof definition admonition" id="definition:covariance-correlation">
<p class="admonition-title"><span class="caption-number">Definition 35.11 </span> (Covariance and correlation)</p>
<section class="definition-content" id="proof-content">
<p>The <strong>covariance</strong>  of two random variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is usually denoted <span class="math notranslate nohighlight">\(\sigma_{XY}^2\)</span> or <span class="math notranslate nohighlight">\(\text{Cov}(X,Y)\)</span> and is defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-42c77f12-fcc2-41c6-ad18-b6ac99bf5247">
<span class="eqno">(35.27)<a class="headerlink" href="#equation-42c77f12-fcc2-41c6-ad18-b6ac99bf5247" title="Permalink to this equation">#</a></span>\[\begin{equation}
\text{Cov}(X,Y) \equiv \sigma_{XY}^2 \equiv \mathbb{E}\left[ \left( X - \mathbb{E}[X] \right) \left( Y - \mathbb{E}[Y] \right)  \right].
\end{equation}\]</div>
<p>The <strong>correlation coefficient</strong> of <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> is defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-1a770611-ba18-4aa1-a721-ecdd2e4e3fc0">
<span class="eqno">(35.28)<a class="headerlink" href="#equation-1a770611-ba18-4aa1-a721-ecdd2e4e3fc0" title="Permalink to this equation">#</a></span>\[\begin{equation}
\rho_{XY} \equiv \frac{\text{Cov}(X,Y)}{\sqrt{\text{Var}(X)\text{Var}(Y)}},
\end{equation}\]</div>
<p>as long as the variances are non-zero.</p>
</section>
</div><p>You can show that the correlation coefficient is <span class="math notranslate nohighlight">\(-1 \leq \rho \leq 1\)</span>. In particular, the diagonal covariance is the variance and therefore <span class="math notranslate nohighlight">\(\rho_{XX} = 1\)</span>.</p>
<p>Two variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are called <em>uncorrelated</em> if Cov<span class="math notranslate nohighlight">\((X,Y)=0\)</span>. Note that the independence property of Eq. <a class="reference internal" href="#equation-eq-statistics-independence">(35.16)</a> implies that two independent variables are always uncorrelated. However, the converse is not necessarily true.</p>
</section>
</section>
<section id="important-distributions">
<h2><span class="section-number">35.3. </span>Important distributions<a class="headerlink" href="#important-distributions" title="Link to this heading">#</a></h2>
<p>Let us consider some important, univariate distributions.</p>
<section id="the-uniform-distribution">
<h3>The uniform distribution<a class="headerlink" href="#the-uniform-distribution" title="Link to this heading">#</a></h3>
<p>The first one is the most basic PDF; namely the uniform distribution. This distribution is constant in a range <span class="math notranslate nohighlight">\([a,b]\)</span> and zero elsewhere. Thus, when a random variable <span class="math notranslate nohighlight">\(X\)</span> is uniformly distributed on <span class="math notranslate nohighlight">\([a,b]\)</span> we can write <span class="math notranslate nohighlight">\(X  \sim \mathcal{U}([a,b])\)</span> with</p>
<div class="amsmath math notranslate nohighlight" id="equation-b48eceab-2bc8-4ab4-b9d4-5d2cd75b9149">
<span class="eqno">(35.29)<a class="headerlink" href="#equation-b48eceab-2bc8-4ab4-b9d4-5d2cd75b9149" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathcal{U}\left( [a,b]\right) = \frac{1}{b-a}\theta(x-a)\theta(b-x).
\label{eq:Statistics:unifromPDF}
\end{equation}\]</div>
<p>For <span class="math notranslate nohighlight">\(a=0\)</span> and <span class="math notranslate nohighlight">\(b=1\)</span> we have the standard uniform distribution</p>
<div class="amsmath math notranslate nohighlight" id="equation-43a46536-7bb2-42d4-9706-884ede02e982">
<span class="eqno">(35.30)<a class="headerlink" href="#equation-43a46536-7bb2-42d4-9706-884ede02e982" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathcal{U}\left( [0,1]\right) = \left\{
\begin{array}{ll}
1 &amp; x \in [0,1],\\
0 &amp; \mathrm{otherwise}
\end{array}
\right.
\end{equation}\]</div>
<p>Note that these functions correspond to properly normalized PDFs such that they give a total probability of one when integrated over <span class="math notranslate nohighlight">\(x \in (-\infty,\infty)\)</span>.</p>
</section>
<section id="gaussian-distribution">
<span id="sec-univariate-gaussian"></span><h3>Gaussian distribution<a class="headerlink" href="#gaussian-distribution" title="Link to this heading">#</a></h3>
<p>The second one is the univariate Gaussian distribution (or normal distribution). A random variable <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(\mu,\sigma^2)\)</span> is normally distributed with mean value <span class="math notranslate nohighlight">\(\mu\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma\)</span> with</p>
<div class="amsmath math notranslate nohighlight" id="equation-f7d159a9-374b-4e36-b4f9-9c24727bfed9">
<span class="eqno">(35.31)<a class="headerlink" href="#equation-f7d159a9-374b-4e36-b4f9-9c24727bfed9" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathcal{N}(\mu,\sigma^2) = \frac{1}{\sigma\sqrt{2\pi}} \exp{(-\frac{(x-\mu)^2}{2\sigma^2})},
\end{equation}\]</div>
<p>the corresponding PDF. If <span class="math notranslate nohighlight">\(\mu=0\)</span> and <span class="math notranslate nohighlight">\(\sigma=1\)</span>, it is called the <strong>standard normal distribution</strong></p>
<div class="amsmath math notranslate nohighlight" id="equation-45a40ce6-80f3-4ab8-82f1-3638538c2f17">
<span class="eqno">(35.32)<a class="headerlink" href="#equation-45a40ce6-80f3-4ab8-82f1-3638538c2f17" title="Permalink to this equation">#</a></span>\[\begin{equation}
\mathcal{N}(0,1) = \frac{1}{\sqrt{2\pi}} \exp{(-\frac{x^2}{2})}.
\end{equation}\]</div>
<p>We sometimes denote distributions using a notation like <span class="math notranslate nohighlight">\(\mathcal{N}(x|\mu,\sigma^2)\)</span>. This should be understood as a variable <span class="math notranslate nohighlight">\(x\)</span> being normally distributed with mean <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
</section>
<section id="multivariate-gaussian-distribution">
<span id="sec-distribution-mvn"></span><h3>Multivariate Gaussian distribution<a class="headerlink" href="#multivariate-gaussian-distribution" title="Link to this heading">#</a></h3>
<p>The univariate <a class="reference internal" href="#sec-univariate-gaussian"><span class="std std-ref">Gaussian distribution</span></a> can be generalized to a multivariate distribution. A multivariate random variable <span class="math notranslate nohighlight">\(\boldsymbol{X} \sim \mathcal{N}(\boldsymbol{\mu},\boldsymbol{\Sigma})\)</span> is normally distributed with mean <em>vector</em> <span class="math notranslate nohighlight">\(\boldsymbol{\mu} \in \mathbb{R}^k\)</span> and covariance <em>matrix</em> <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma} \in \mathbb{R}^{k \times k}\)</span> with</p>
<div class="math notranslate nohighlight" id="equation-eq-statistics-multivariate-normal-pdf">
<span class="eqno">(35.33)<a class="headerlink" href="#equation-eq-statistics-multivariate-normal-pdf" title="Link to this equation">#</a></span>\[
\mathcal{N}(\boldsymbol{\mu},\boldsymbol{\Sigma}) = \frac{1}{(2\pi)^{k/2} |\boldsymbol{\Sigma}|^{1/2}} \exp{ \left( -\frac{1}{2}(\boldsymbol{x} - \boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\boldsymbol{x} - \boldsymbol{\mu})\right)}.
\]</div>
<p>This distribution only exists for a positive definite covariance matrix <span class="math notranslate nohighlight">\(\boldsymbol{\Sigma}\)</span>.</p>
</section>
</section>
<section id="quick-introduction-to-scipy-stats">
<h2><span class="section-number">35.4. </span>Quick introduction to  <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code><a class="headerlink" href="#quick-introduction-to-scipy-stats" title="Link to this heading">#</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> module contains a large number of probability distributions, summary and frequency statistics, correlation functions statistical tests, and more. If you google <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code>, youâ€™ll likely get the manual page as the first hit: <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/stats.html">https://docs.scipy.org/doc/scipy/reference/stats.html</a>. Here youâ€™ll find a long list of the continuous and discrete distributions that are available for creating random variables, followed (scroll way down) by different methods (functions) to extract properties of a distribution (called Summary statistics) and to perform many other statistical tasks.</p>
<p>Follow the link for any of the distributions (your choice!) to find its mathematical definition, some examples of how to use it, and a list of methods. Some methods of particular interest are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mean()</span></code> - Mean of the distribution.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">median()</span></code> - Median of the distribution.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pdf(x)</span></code> - Value of the probability density function at x.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rvs(size=numpts)</span></code> - generate numpts random values of the pdf.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">interval(alpha)</span></code> - Endpoints of the range that contains alpha percent of the distribution.</p></li>
</ul>
<section id="code-example">
<h3>Code example<a class="headerlink" href="#code-example" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">stats</span>

<span class="c1"># Define a normally distributed random variable with mean=1.0 and standard deviation = 2.0</span>
<span class="n">my_norm_rv</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

<span class="c1"># Extract and print the mean and variance</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The mean is </span><span class="si">{</span><span class="n">my_norm_rv</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">3.1f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The variance is </span><span class="si">{</span><span class="n">my_norm_rv</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s1">3.1f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># The 68% credible interval (approximately one sigma)</span>
<span class="p">(</span><span class="n">min68</span><span class="p">,</span><span class="n">max68</span><span class="p">)</span> <span class="o">=</span> <span class="n">my_norm_rv</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mf">0.68</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The 68% credible interval is [</span><span class="si">{</span><span class="n">min68</span><span class="si">:</span><span class="s1">4.2f</span><span class="si">}</span><span class="s1">,</span><span class="si">{</span><span class="n">max68</span><span class="si">:</span><span class="s1">4.2f</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>

<span class="c1"># Draw five random samples. Note that the last output will be printed.</span>
<span class="n">my_norm_rv</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The mean is 1.0
The variance is 4.0
The 68% credible interval is [-0.99,2.99]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 2.41130578,  0.58306299,  0.30092513,  1.94991266, -0.36069653])
</pre></div>
</div>
</div>
</div>
<p>Create a plot to compare the line shape of the PDF with a histogram of a large number of samples from the PDF.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">)})</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">my_norm_rv</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.001</span><span class="p">),</span>
                <span class="n">my_norm_rv</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.999</span><span class="p">),</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">my_norm_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
       <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;pdf&#39;</span><span class="p">)</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">my_norm_rv</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p(x)$&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/19a32f88223b2290d4d641c911c31b61a258df4f9975e70afeec4ac006a31774.png" src="../../_images/19a32f88223b2290d4d641c911c31b61a258df4f9975e70afeec4ac006a31774.png" />
</div>
</div>
</section>
<section id="pseudo-random-number-generator">
<h3>(Pseudo) random number generator<a class="headerlink" href="#pseudo-random-number-generator" title="Link to this heading">#</a></h3>
<p>Random numbers generated by a computer are, in fact, not random at all. They are deterministically determined from a sequence of numbers that look random. The method to generate this sequence is known as a <em>pseudo random number generator</em> (PRNG), but will not be described here.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> module uses <code class="docutils literal notranslate"><span class="pre">numpy</span></code> functionality to generate random numbers and sample the distribution for a random variable. In fact, many of the standard distributions are built into <code class="docutils literal notranslate"><span class="pre">numpy</span></code> and if all you need is fast sampling of random numbers then you can often use <code class="docutils literal notranslate"><span class="pre">numpy</span></code> directly without the need for <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code>.</p>
<p>The lack of true randomness can be turned into a feature since it allows for experimentation, reproducibility and unit testing of code that uses stochastic modelling. The sequence of random numbers is determined by: (i) the choice of PRNG algorithm, and (ii) a seed to start the generation. Therefore, we can generate the same random numbers in two different runs by specifying the same PRNG and seed. In <code class="docutils literal notranslate"><span class="pre">numpy</span></code> the recommended procedure for random number sampling is to create a <code class="docutils literal notranslate"><span class="pre">Generator</span></code> instance with <code class="docutils literal notranslate"><span class="pre">default_rng</span></code> and call the relevant methods as attributes to this instance. In the code below, we illustrate this procedure to collect five samples from a standard normal distribution using both <code class="docutils literal notranslate"><span class="pre">numpy</span></code> and <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code>. You should get the same output if you run this code locally.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">stats</span>
<span class="c1"># seed number</span>
<span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="c1"># Generator instance initialized with the seed</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;numpy samples from N(0,1) with </span><span class="si">{</span><span class="n">rng</span><span class="si">}</span><span class="s1"> and seed=</span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1">: &#39;</span><span class="p">)</span>
<span class="c1"># Use numpy to collect samples from a standard normal</span>
<span class="n">np_random_numbers</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np_random_numbers</span><span class="p">)</span>

<span class="c1"># The same with scipy.stats</span>
<span class="c1"># Create the random variable</span>
<span class="n">my_norm_rv</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="c1"># sample, using the same PRNG and seed as before</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;scipy.stats samples from N(0,1) with </span><span class="si">{</span><span class="n">rng</span><span class="si">}</span><span class="s1"> and seed=</span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1">: &#39;</span><span class="p">)</span>
<span class="n">stats_random_numbers</span> <span class="o">=</span> <span class="n">my_norm_rv</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stats_random_numbers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>numpy samples from N(0,1) with Generator(PCG64) and seed=42: 
[ 0.30471708 -1.03998411  0.7504512   0.94056472 -1.95103519]
scipy.stats samples from N(0,1) with Generator(PCG64) and seed=42: 
[ 0.30471708 -1.03998411  0.7504512   0.94056472 -1.95103519]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="point-estimates-and-credible-regions">
<span id="sec-point-and-credibility"></span><h2><span class="section-number">35.5. </span>Point estimates and credible regions<a class="headerlink" href="#point-estimates-and-credible-regions" title="Link to this heading">#</a></h2>
<p>We will use PDFs to quantify the strength of our inference processes. However, one might be in a situation where it is desirable to summarize the information contained in a PDF in a single (or a few) numbers. This is not always easy, but some common choices are listed here.</p>
<section id="mean-median-mode">
<h3>Mean, median, mode<a class="headerlink" href="#mean-median-mode" title="Link to this heading">#</a></h3>
<p>The values of the <strong>mode</strong>, <strong>mean</strong>, and <strong>median</strong> can all be used as point estimates for the â€œmost probableâ€ value of <span class="math notranslate nohighlight">\(X\)</span>. The mode is the position of the peak of the PDF, the mean was defined in Eq. <a class="reference internal" href="#equation-eq-statistics-mean">(35.22)</a>, while the median is the value <span class="math notranslate nohighlight">\(\mu_{1/2}\)</span> for which <span class="math notranslate nohighlight">\(P(\mu_{1/2}) = 0.5\)</span>. For some PDFs, these metrics will all be the same as exemplified in the first and last panel of <a class="reference internal" href="#fig-pdfs"><span class="std std-numref">Fig. 35.1</span></a>. For others, such as exemplified in the middle panel, they will not.</p>
<p>Let us consider three example PDFs that illustrate some of the features of the different point estimates and the problems that might occur.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_point</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">)})</span>
<span class="n">my_rvs</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">scale</span><span class="o">=</span><span class="mi">4</span><span class="p">),</span><span class="n">stats</span><span class="o">.</span><span class="n">invgamma</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">5.0</span><span class="p">),</span><span class="n">stats</span><span class="o">.</span><span class="n">beta</span><span class="p">(</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">)]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">30</span><span class="p">,</span><span class="mi">10000</span><span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">my_rv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span><span class="n">my_rvs</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">my_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
           <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="c1"># Find and plot the mean</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">my_rv</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;mean&#39;</span><span class="p">)</span>
    <span class="c1"># Find and plot the median</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">my_rv</span><span class="o">.</span><span class="n">median</span><span class="p">(),</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-.&#39;</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">)</span>
    <span class="c1"># Find and plot the mode(s)</span>
    <span class="n">modes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">my_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">&gt;</span><span class="n">my_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">2</span><span class="p">]),</span>
                           <span class="n">my_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">&gt;</span><span class="n">my_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">:]))</span>
    <span class="k">for</span> <span class="n">xmode</span> <span class="ow">in</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">modes</span><span class="p">]:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">xmode</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;mode&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ax</span><span class="o">==</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> 
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p(x)$&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">);</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ax</span><span class="o">==</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">15</span><span class="p">)</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">myst_nb</span><span class="w"> </span><span class="kn">import</span> <span class="n">glue</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;pointestimates_fig&quot;</span><span class="p">,</span> <span class="n">fig_point</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<img alt="../../_images/9cbcfa391cd30ce9c4c13561ddd6e96a91c298088261337228628923d0881d29.png" src="../../_images/9cbcfa391cd30ce9c4c13561ddd6e96a91c298088261337228628923d0881d29.png" />
</div>
</details>
</div>
<figure class="align-default" id="fig-pdfs">
<img alt="../../_images/9cbcfa391cd30ce9c4c13561ddd6e96a91c298088261337228628923d0881d29.png" src="../../_images/9cbcfa391cd30ce9c4c13561ddd6e96a91c298088261337228628923d0881d29.png" />
<figcaption>
<p><span class="caption-number">Fig. 35.1 </span><span class="caption-text">The mean, median and modes(s) for some exampls PDFs. For some PDFs, several or all of these metrics are the same. For others they are not. The position of the mean is largely affected by long tails as illustrated in the middle panel. The PDF in the right panel has two modes (it is bimodal). Although no shuch example is shown here, there are PDFs for which the mean is not defined.</span><a class="headerlink" href="#fig-pdfs" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="admonition-discuss admonition">
<p class="admonition-title">Discuss</p>
<p>Which point estimate do you consider most representative for the different PDFs?</p>
</div>
</section>
<section id="credible-regions">
<h3>Credible regions<a class="headerlink" href="#credible-regions" title="Link to this heading">#</a></h3>
<p>The integration of the PDF over some domain translates into a probability. It is therefore possible to identify regions <span class="math notranslate nohighlight">\(\mathbb{D}_P\)</span> for which the integrated probability equals some desired value <span class="math notranslate nohighlight">\(P\)</span>, i.e.,</p>
<div class="amsmath math notranslate nohighlight" id="equation-034b5f70-91fc-4fd0-a773-5f39928b3856">
<span class="eqno">(35.34)<a class="headerlink" href="#equation-034b5f70-91fc-4fd0-a773-5f39928b3856" title="Permalink to this equation">#</a></span>\[\begin{equation}
  P = \int_{\mathbb{D}_P} p(x_1, x_2, \ldots) dx_1 dx_2 \ldots
\end{equation}\]</div>
<p>This allows to make statements such as: â€œThere is a 50% probability that the parameters are found within the domain <span class="math notranslate nohighlight">\(\mathbb{D}_{0.5}\)</span>â€â€. However, the identification of such a domain is not unique. Two popular choices are</p>
<ol class="arabic">
<li><p><strong>Highest-density regions</strong> (HDR)</p>
<p>The HDR is the smallest possible domain that gives the desired probability mass. That is</p>
<div class="amsmath math notranslate nohighlight" id="equation-2baf3af4-d75d-4243-96c6-3723773a509c">
<span class="eqno">(35.35)<a class="headerlink" href="#equation-2baf3af4-d75d-4243-96c6-3723773a509c" title="Permalink to this equation">#</a></span>\[\begin{equation}
p(\boldsymbol{x}) \geq p(\boldsymbol{y}), \quad \text{when } \boldsymbol{x} \in \mathbb{D}_P \text{ and } \boldsymbol{y} \notin \mathbb{D}_P.
\end{equation}\]</div>
</li>
<li><p><strong>Equal-tailed interval</strong> (ETI)</p>
<p>For a univariate PDF we can define an interval <span class="math notranslate nohighlight">\([a,b]\)</span> such that <span class="math notranslate nohighlight">\(\int_a^b p(x) dx = P\)</span> and the probability mass on either side (the tails) are equal. The end points of this ETI fulfil</p>
<div class="amsmath math notranslate nohighlight" id="equation-a47d50e6-7d6e-42b3-88ec-c7de6e7e962e">
<span class="eqno">(35.36)<a class="headerlink" href="#equation-a47d50e6-7d6e-42b3-88ec-c7de6e7e962e" title="Permalink to this equation">#</a></span>\[\begin{equation}
P(a) = 1-P(b) = \frac{1-P}{2}.
\end{equation}\]</div>
</li>
</ol>
<div class="admonition-discuss admonition">
<p class="admonition-title">Discuss</p>
<p>How would you describe a multimodal PDF using these metrics?</p>
</div>
<p>Let us again consider the three example PDFs from above.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig_CR</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="s2">&quot;figsize&quot;</span><span class="p">:(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">)})</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">my_rv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span><span class="n">my_rvs</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">my_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>
           <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
    <span class="c1"># Find and plot the 68% credible interval</span>
    <span class="p">(</span><span class="n">min68</span><span class="p">,</span><span class="n">max68</span><span class="p">)</span> <span class="o">=</span> <span class="n">my_rv</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mf">0.68</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">min68</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">max68</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">my_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">where</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="n">min68</span><span class="p">,</span><span class="n">x</span><span class="o">&lt;</span><span class="n">max68</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="c1"># Find and plot the 90% credible interval</span>
    <span class="p">(</span><span class="n">min90</span><span class="p">,</span><span class="n">max90</span><span class="p">)</span> <span class="o">=</span> <span class="n">my_rv</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mf">0.90</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">min90</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">max90</span><span class="p">,</span><span class="n">ls</span><span class="o">=</span><span class="s1">&#39;:&#39;</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">my_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span><span class="n">where</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">x</span><span class="o">&gt;</span><span class="n">min90</span><span class="p">,</span><span class="n">x</span><span class="o">&lt;</span><span class="n">max90</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ax</span><span class="o">==</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span> 
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p(x)$&#39;</span><span class="p">);</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">ax</span><span class="o">==</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">15</span><span class="p">)</span>
    <span class="n">glue</span><span class="p">(</span><span class="s2">&quot;credibleregions_fig&quot;</span><span class="p">,</span> <span class="n">fig_CR</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<img alt="../../_images/60b00953b96649a5dce2c9366ed8db5f1cb37b7f0446b1defe3a040859127bdb.png" src="../../_images/60b00953b96649a5dce2c9366ed8db5f1cb37b7f0446b1defe3a040859127bdb.png" />
</div>
</details>
</div>
<figure class="align-default" id="fig-pdfs-cr">
<img alt="../../_images/60b00953b96649a5dce2c9366ed8db5f1cb37b7f0446b1defe3a040859127bdb.png" src="../../_images/60b00953b96649a5dce2c9366ed8db5f1cb37b7f0446b1defe3a040859127bdb.png" />
<figcaption>
<p><span class="caption-number">Fig. 35.2 </span><span class="caption-text">The 68/90 percent credible regions of some example PDFs are shown in dark/light shading. These are all equal-tailed intervals.</span><a class="headerlink" href="#fig-pdfs-cr" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Let us also look at a multivariate PDF. The example below is a bivariate normal distribution with non-zero off-diagonal covariance. It is represented by a so called <strong>corner plot</strong> of a large number of samples. The bivariate distribution is shown in the lower left panel, while the two marginal ones are shown on the diagonal.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">]])</span>
<span class="n">my_multinorm_rv</span><span class="o">=</span><span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span><span class="n">cov</span><span class="o">=</span><span class="n">cov</span><span class="p">)</span>
<span class="n">x1x2</span><span class="o">=</span><span class="n">my_multinorm_rv</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>

<span class="c1"># We use the prettyplease package from</span>
<span class="c1"># https://github.com/svisak/prettyplease</span>
<span class="c1"># which is in the ../Utils directory</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="c1"># Adding ../Utils/ to the python module search path</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s1">&#39;../Utils/&#39;</span><span class="p">))</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">prettyplease.prettyplease</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pp</span>

<span class="n">fig_x1x2</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">corner</span><span class="p">(</span><span class="n">x1x2</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="sa">r</span><span class="s1">&#39;$x_1$&#39;</span><span class="p">,</span><span class="sa">r</span><span class="s1">&#39;$x_2$&#39;</span><span class="p">],</span> 
                          <span class="n">quantiles</span><span class="o">=</span><span class="p">[</span><span class="mf">0.16</span><span class="p">,</span> <span class="mf">0.84</span><span class="p">],</span> <span class="n">levels</span><span class="o">=</span><span class="p">(</span><span class="mf">0.68</span><span class="p">,</span><span class="mf">0.9</span><span class="p">),</span><span class="n">linewidth</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                          <span class="n">plot_estimates</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">n_uncertainty_digits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                          <span class="n">title_loc</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">glue</span><span class="p">(</span><span class="s2">&quot;bivariate_fig&quot;</span><span class="p">,</span> <span class="n">fig_x1x2</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<img alt="../../_images/a5096715f0ea70692cbbaa4290532d91d9a0b72d4980a2c00beb17230344873c.png" src="../../_images/a5096715f0ea70692cbbaa4290532d91d9a0b72d4980a2c00beb17230344873c.png" />
</div>
</details>
</div>
<figure class="align-default" id="fig-bivariate-cr">
<img alt="../../_images/a5096715f0ea70692cbbaa4290532d91d9a0b72d4980a2c00beb17230344873c.png" src="../../_images/a5096715f0ea70692cbbaa4290532d91d9a0b72d4980a2c00beb17230344873c.png" />
<figcaption>
<p><span class="caption-number">Fig. 35.3 </span><span class="caption-text">A corner plot of a bivariate normal PDF. The 68% and 90% credible regions are indicated by level curves in the lower left panel. Note the anti-correlation between the two variables (the correlation coefficient is <span class="math notranslate nohighlight">\(\rho_{12}=-0.5\)</span>). The marginal distributions for <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> are shown in the diagonal panels with the dashed lines indicating the corresponding 68% credible intervals. Note that the marginal PDFs are univariate normal distributions.</span><a class="headerlink" href="#fig-bivariate-cr" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="types-of-probability">
<h2><span class="section-number">35.6. </span>Types of probability<a class="headerlink" href="#types-of-probability" title="Link to this heading">#</a></h2>
<p>As we have shown, we construct a probability space by assigning a numerical probability in the range [0,1] to events (sets of outcomes) in some space.</p>
<p>When outcomes are the result of an uncertain but repeatable process, probabilities can always be measured to arbitrary accuracy by simply observing many repetitions of the process and calculating the frequency at which each event occurs. These <strong>frequentist probabilities</strong> have an appealing objective reality to them.</p>
<div class="admonition-discuss admonition">
<p class="admonition-title">Discuss</p>
<p>How might you assign a frequentist probability to statements like:</p>
<ul class="simple">
<li><p>The electron spin is 1/2.</p></li>
<li><p>The Higgs boson mass is between 124 and 126 GeV.</p></li>
<li><p>The fraction of dark energy in the universe today is between 68% and 70%.</p></li>
<li><p>The superconductor Hg-1223 has a critical temperature above 130K.</p></li>
</ul>
</div>
<p>The answer is that you cannot (if we assume that these are universal constants), since that would require a measurable process whose outcomes had different (random) values for the corresponding universal constant. Or maybe you could if you had access to a number of multiverses with different universal constants in each.</p>
<p>The inevitable conclusion is that the statements we scientists are most interested in cannot be assigned frequentist probabilities.</p>
<p>However, if we allow probabilities to also measure our subjective â€œdegree of beliefâ€ in a statement, then we can use the full machinery of probability theory to discuss more interesting statements. These are called <strong>Bayesian probabilities</strong>. Note that such probabilities are always conditional in the sense that they are statements based on given information.</p>
<p>Roughly speaking, the choice is between:</p>
<dl class="simple myst">
<dt>Frequentist statistics</dt><dd><p>objective probabilities of uninteresting statements.</p>
</dd>
<dt>Bayesian statistics</dt><dd><p>subjective probabilities of interesting statements.</p>
</dd>
</dl>
</section>
<section id="exercises">
<h2><span class="section-number">35.7. </span>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<div class="exercise admonition" id="exercise:Statistics:colorblind">

<p class="admonition-title"><span class="caption-number">Exercise 35.1 </span> (Random and colorblind)</p>
<section id="exercise-content">
<p>The gene responsible for color blindness is located on the X chromosome. In other words, red-green color blindness is an X-linked recessive condition and is much more common in males (with only one X chromosome).
According to the Howard Hughes medical institute about 7% of men and 0.4% of women are red-green colorblind. Furthermore, sccording to SCB, the Swedish population is 50,3% male and 49,7% female. What is the probability that a person selcted at random is colorblind?</p>
</section>
</div>
<div class="exercise admonition" id="exercise:Statistics:conditional-discrete-pmf">

<p class="admonition-title"><span class="caption-number">Exercise 35.2 </span> (Conditional discrete probability mass function)</p>
<section id="exercise-content">
<p>The joint probability mass function of the discrete variables <span class="math notranslate nohighlight">\(X,Y\)</span> is</p>
<div class="math notranslate nohighlight">
\[
p(x,y) = \frac{x+y}{18}, \quad \text{for } x,y \in \{0,1,2\}.
\]</div>
<ul class="simple">
<li><p>Find the conditional probability mass function <span class="math notranslate nohighlight">\(\pdf{y}{x}\)</span>.</p></li>
<li><p>Verify that it is properly normalized.</p></li>
</ul>
</section>
</div>
<div class="exercise admonition" id="exercise:Statistics:conditional-probability-continuous">

<p class="admonition-title"><span class="caption-number">Exercise 35.3 </span> (Conditional probability for continuous variables)</p>
<section id="exercise-content">
<p>The continuous random variables <span class="math notranslate nohighlight">\(X,Y\)</span> have the joint density</p>
<div class="math notranslate nohighlight">
\[
p(x,y) = e^{-x}, \quad \text{for } 0 &lt; y &lt; x &lt; \infty.
\]</div>
<p>Find the probability <span class="math notranslate nohighlight">\(\cprob{Y&lt;2}{X=5}\)</span>.</p>
</section>
</div>
<div class="exercise admonition" id="exercise:Statistics:conditional-expectation">

<p class="admonition-title"><span class="caption-number">Exercise 35.4 </span> (Conditional expectation)</p>
<section id="exercise-content">
<p>Assume that the continuous random variables <span class="math notranslate nohighlight">\(X,Y\)</span> have the joint density</p>
<div class="math notranslate nohighlight">
\[
\p{x,y} = \frac{2}{xy}, \quad \text{for } 1 &lt; y &lt; x &lt; e.
\]</div>
<p>Find the conditional expectation <span class="math notranslate nohighlight">\(\expect{Y \vert X=x}\)</span>.</p>
</section>
</div>
<div class="exercise admonition" id="exercise:Statistics:scipy-stats">

<p class="admonition-title"><span class="caption-number">Exercise 35.5 </span> (Scipy.stats)</p>
<section id="exercise-content">
<p>Use <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> to</p>
<ul class="simple">
<li><p>Find and print the mean and the variance;</p></li>
<li><p>Find and print the 68% credible region (equal-tail interval);</p></li>
<li><p>Draw and print 5 random samples;</p></li>
<li><p>Plot the pdf (including at least 90% of the probability mass);</p></li>
</ul>
<p>for</p>
<ol class="arabic simple">
<li><p>A student-t distribution with <span class="math notranslate nohighlight">\(\nu=2\)</span> degrees-of-freedom;</p></li>
<li><p>A student-t distribution with <span class="math notranslate nohighlight">\(\nu=100\)</span> degrees-of-freedom;</p></li>
<li><p>A standard normal distribution;</p></li>
</ol>
<p>in all cases with the mode at 0.0.</p>
</section>
</div>
<div class="exercise admonition" id="exercise:Statistics:bivariate-pdf">

<p class="admonition-title"><span class="caption-number">Exercise 35.6 </span> (Bivariate pdf)</p>
<section id="exercise-content">
<p>Consider the following (multimodal) bivariate pdf</p>
<div class="math notranslate nohighlight">
\[
\p{x,y} = A_1 \exp\left(- \frac{(x-x_1)^2 + (y-y_1)^2}{2\sigma_1^2} \right) + 
A_2 \exp\left(- \frac{(x-x_2)^2 + (y-y_2)^2}{2\sigma_2^2} \right),
\]</div>
<p>with <span class="math notranslate nohighlight">\(A_1=4.82033\)</span>, <span class="math notranslate nohighlight">\(x_1=0.5\)</span>, <span class="math notranslate nohighlight">\(y_1=0.5\)</span>, <span class="math notranslate nohighlight">\(\sigma_1=0.2\)</span>, and <span class="math notranslate nohighlight">\(A_2=4.43181\)</span>, <span class="math notranslate nohighlight">\(x_2=0.65\)</span>, <span class="math notranslate nohighlight">\(y_2=0.75\)</span>, <span class="math notranslate nohighlight">\(\sigma_2=0.04\)</span>.</p>
<p>Consider the domain <span class="math notranslate nohighlight">\(x,y \in [0,1]\)</span> and use relevant python modules / methods to</p>
<ul class="simple">
<li><p>Plot contour levels of this pdf (useful methods: <code class="docutils literal notranslate"><span class="pre">np.meshgrid</span></code> and <code class="docutils literal notranslate"><span class="pre">plt.contour</span></code>);</p></li>
<li><p>Make a three-dimensional plot of the pdf (useful methods: <code class="docutils literal notranslate"><span class="pre">plt.subplots(subplot_kw={&quot;projection&quot;:</span> <span class="pre">&quot;3d&quot;})</span></code> and <code class="docutils literal notranslate"><span class="pre">plt.plot_surface</span></code>);</p></li>
<li><p>Compute and plot the marginal pdf <span class="math notranslate nohighlight">\(\p{y}\)</span> (useful method: <code class="docutils literal notranslate"><span class="pre">scipy.integrate.quad</span></code>)</p></li>
</ul>
</section>
</div>
</section>
<section id="solutions">
<h2><span class="section-number">35.8. </span>Solutions<a class="headerlink" href="#solutions" title="Link to this heading">#</a></h2>
<div class="solution dropdown admonition" id="solution:Statistics:colorblind">

<p class="admonition-title">Solution to<a class="reference internal" href="#exercise:Statistics:colorblind"> Exercise 35.1 (Random and colorblind)</a></p>
<section id="solution-content">
<p>Let <span class="math notranslate nohighlight">\(C\)</span>, <span class="math notranslate nohighlight">\(M\)</span>, <span class="math notranslate nohighlight">\(F\)</span> denote the events that a random person is colorblind, male, and female, respectively. By the law of total probability</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
\prob{(C)} &amp;= \cprob{C}{M}\prob{(M)} + \cprob{C}{F}\prob{(F)} \\
&amp;(0.07)(0.503) + (0.004)(0.497) = 0.037.
\end{align*}\]</div>
</section>
</div>
<div class="solution dropdown admonition" id="solution:Statistics:conditional-discrete-pmf">

<p class="admonition-title">Solution to<a class="reference internal" href="#exercise:Statistics:conditional-discrete-pmf"> Exercise 35.2 (Conditional discrete probability mass function)</a></p>
<section id="solution-content">
<p>The conditional probability mass function can be obtained from the ratio</p>
<div class="math notranslate nohighlight">
\[
\pdf{y}{x} = \frac{p(x,y)}{p(x)}.
\]</div>
<p>Let us therefore find the marginal probability mass function</p>
<div class="math notranslate nohighlight">
\[
p(x) = \sum_{y=0}^2 p(x,y) = \frac{x}{18} + \frac{x+1}{18} + \frac{x+2}{18} = \frac{x+1}{6}.
\]</div>
<p>Thus we get <span class="math notranslate nohighlight">\(\pdf{y}{x} = \frac{(x+y)/18}{(x+1)/6} = \frac{x+y}{3(x+1)}\)</span> for <span class="math notranslate nohighlight">\(y \in \{0,1,2\}\)</span>.</p>
<p>We find that this pdf (over <span class="math notranslate nohighlight">\(y\)</span>) is properly normalized since</p>
<div class="math notranslate nohighlight">
\[
\sum_{y=0}^2 \pdf{y}{x} = \frac{x+0+x+1+x+2}{3(x+1)} = 1.
\]</div>
</section>
</div>
<div class="solution dropdown admonition" id="solution:Statistics:conditional-probability-continuous">

<p class="admonition-title">Solution to<a class="reference internal" href="#exercise:Statistics:conditional-probability-continuous"> Exercise 35.3 (Conditional probability for continuous variables)</a></p>
<section id="solution-content">
<p>The desired probability is</p>
<div class="math notranslate nohighlight">
\[
\cprob{Y&lt;2}{X=5} = \int_0^2 p_{Y|X}(y \vert 5) dy.
\]</div>
<p>To find the conditional density <span class="math notranslate nohighlight">\(p_{Y|X}(y \vert x)\)</span> we need the marginal one</p>
<div class="math notranslate nohighlight">
\[
\p{x} = \int_0^\infty \p{x,y} dy = \int_0^x e^{-x} dy = x e^{-x},
\]</div>
<p>for <span class="math notranslate nohighlight">\(x &gt; 0\)</span>. This gives</p>
<div class="math notranslate nohighlight">
\[
p_{Y|X}(y \vert x) = \frac{\p{x,y}}{\p{x}} = \frac{e^{-x}}{x e^{-x}} \frac{1}{x},
\]</div>
<p>for <span class="math notranslate nohighlight">\(0 &lt; y &lt; x\)</span>. Note that this is a uniform distribution for <span class="math notranslate nohighlight">\(y\)</span> given <span class="math notranslate nohighlight">\(x\)</span>. Therefore</p>
<div class="math notranslate nohighlight">
\[
\cprob{Y&lt;2}{X=5} = \int_0^2 \frac{1}{5} dy = \frac{2}{5}.
\]</div>
</section>
</div>
<div class="solution dropdown admonition" id="solution:Statistics:conditional-expectation">

<p class="admonition-title">Solution to<a class="reference internal" href="#exercise:Statistics:conditional-expectation"> Exercise 35.4 (Conditional expectation)</a></p>
<section id="solution-content">
<p>We need the marginal density</p>
<div class="math notranslate nohighlight">
\[
\p{x} = \int_1^x \frac{2}{xy} dy = \frac{2 \ln x}{x}, \quad \text{for } 1 &lt; x &lt; e,
\]</div>
<p>to get the conditional one</p>
<div class="math notranslate nohighlight">
\[
p_{Y|X}(y|x) = \frac{2/xy}{2 \ln x / x} = \frac{1}{y\ln x}, \quad \text{for } 1 &lt; y &lt; x.
\]</div>
<p>The conditioned expectation is therefore</p>
<div class="math notranslate nohighlight">
\[
\expect{Y \vert X=x} = \int_1^x y p_{Y|X}(y|x)  dy = \int_1^x \frac{y}{y\ln x} dy = \frac{x-1}{\ln x}.
\]</div>
</section>
</div>
<div class="solution dropdown admonition" id="colution:Statistics:scipy-stats">

<p class="admonition-title">Solution to<a class="reference internal" href="#exercise:Statistics:scipy-stats"> Exercise 35.5 (Scipy.stats)</a></p>
<section id="solution-content">
<p>See the code example in the hidden code block below.</p>
</section>
</div>
<div class="cell tag_hide-cell docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell content</p>
<p class="expanded admonition-title">Hide code cell content</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Define a student-t distribution with location=0.0 and scale = 1.0</span>
<span class="c1"># and \nu=2 degreefs of freedom </span>
<span class="n">df</span><span class="o">=</span><span class="mi">2</span>
<span class="n">my_student_t_rv</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="c1"># An appropriate mesh for plotting</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.05</span><span class="p">),</span><span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.95</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=========</span><span class="se">\n</span><span class="s1"> Student-t distribution df=</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="se">\n</span><span class="s1">=========&#39;</span><span class="p">)</span>
<span class="c1"># Extract and print the mean and variance</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The mean is </span><span class="si">{</span><span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">3.1f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The variance is </span><span class="si">{</span><span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s1">3.1f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># The 68% credible interval (approximately one sigma)</span>
<span class="p">(</span><span class="n">min68</span><span class="p">,</span><span class="n">max68</span><span class="p">)</span> <span class="o">=</span> <span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mf">0.68</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The 68% credible interval is [</span><span class="si">{</span><span class="n">min68</span><span class="si">:</span><span class="s1">4.2f</span><span class="si">}</span><span class="s1">,</span><span class="si">{</span><span class="n">max68</span><span class="si">:</span><span class="s1">4.2f</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>

<span class="c1"># Draw random samples.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
<span class="c1"># Plot</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Student-t (df=</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

<span class="c1"># Define a student-t distribution with location=0.0 and scale = 1.0</span>
<span class="c1"># and \nu=100 degreefs of freedom </span>
<span class="n">df</span><span class="o">=</span><span class="mi">100</span>
<span class="n">my_student_t_rv</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=========</span><span class="se">\n</span><span class="s1"> Student-t distribution df=</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="se">\n</span><span class="s1">=========&#39;</span><span class="p">)</span>
<span class="c1"># Extract and print the mean and variance</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The mean is </span><span class="si">{</span><span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">3.1f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The variance is </span><span class="si">{</span><span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s1">3.1f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># The 68% credible interval (approximately one sigma)</span>
<span class="p">(</span><span class="n">min68</span><span class="p">,</span><span class="n">max68</span><span class="p">)</span> <span class="o">=</span> <span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mf">0.68</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The 68% credible interval is [</span><span class="si">{</span><span class="n">min68</span><span class="si">:</span><span class="s1">4.2f</span><span class="si">}</span><span class="s1">,</span><span class="si">{</span><span class="n">max68</span><span class="si">:</span><span class="s1">4.2f</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>

<span class="c1"># Draw random samples.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
<span class="c1"># Plot</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">my_student_t_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s1">&#39;r--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Student-t (df=</span><span class="si">{</span><span class="n">df</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

<span class="c1"># Define a normal distribution with location=0.0 and scale = 1.0</span>
<span class="n">scale</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">my_normal_rv</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;=========</span><span class="se">\n</span><span class="s1"> Normal distribution (sigma = </span><span class="si">{</span><span class="n">scale</span><span class="si">:</span><span class="s1">3.1f</span><span class="si">}</span><span class="s1">)</span><span class="se">\n</span><span class="s1">=========&#39;</span><span class="p">)</span>
<span class="c1"># Extract and print the mean and variance</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The mean is </span><span class="si">{</span><span class="n">my_normal_rv</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s1">3.1f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The variance is </span><span class="si">{</span><span class="n">my_normal_rv</span><span class="o">.</span><span class="n">var</span><span class="p">()</span><span class="si">:</span><span class="s1">3.1f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># The 68% credible interval (approximately one sigma)</span>
<span class="p">(</span><span class="n">min68</span><span class="p">,</span><span class="n">max68</span><span class="p">)</span> <span class="o">=</span> <span class="n">my_normal_rv</span><span class="o">.</span><span class="n">interval</span><span class="p">(</span><span class="mf">0.68</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;The 68% credible interval is [</span><span class="si">{</span><span class="n">min68</span><span class="si">:</span><span class="s1">4.2f</span><span class="si">}</span><span class="s1">,</span><span class="si">{</span><span class="n">max68</span><span class="si">:</span><span class="s1">4.2f</span><span class="si">}</span><span class="s1">]&#39;</span><span class="p">)</span>

<span class="c1"># Draw random samples.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">my_normal_rv</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>
<span class="c1"># Plot</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">my_normal_rv</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="s1">&#39;g-.&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">fr</span><span class="s1">&#39;Normal ($\sigma$=</span><span class="si">{</span><span class="n">scale</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p(x)$&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=========
 Student-t distribution df=2
=========
The mean is 0.0
The variance is inf
The 68% credible interval is [-1.31,1.31]
[-0.60588678 -0.43978348 -4.39272304  1.17751148 -1.43499246]
=========
 Student-t distribution df=100
=========
The mean is 0.0
The variance is 1.0
The 68% credible interval is [-1.00,1.00]
[ 0.7844437  -1.6047566  -0.52187145  0.64602057 -0.14283535]
=========
 Normal distribution (sigma = 1.0)
=========
The mean is 0.0
The variance is 1.0
The 68% credible interval is [-0.99,0.99]
[ 0.1519963   0.42943957 -0.62237076 -0.93509548 -0.11616986]
</pre></div>
</div>
<img alt="../../_images/590a2834534f86cd102b3942c0ed58c475a43b045dc4f46a5c79b2b71e0dae7b.png" src="../../_images/590a2834534f86cd102b3942c0ed58c475a43b045dc4f46a5c79b2b71e0dae7b.png" />
</div>
</details>
</div>
<div class="solution dropdown admonition" id="solution:Statistics:bivariate-pdf">

<p class="admonition-title">Solution to<a class="reference internal" href="#exercise:Statistics:bivariate-pdf"> Exercise 35.6 (Bivariate pdf)</a></p>
<section id="solution-content">
<p>See the code example in the hidden code block below.</p>
</section>
</div>
<div class="cell tag_hide-cell docutils container">
<details class="admonition hide above-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell content</p>
<p class="expanded admonition-title">Hide code cell content</p>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">cm</span>

<span class="k">def</span><span class="w"> </span><span class="nf">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">A1</span><span class="o">=</span><span class="mf">4.82033</span><span class="p">,</span><span class="n">x1</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">y1</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span><span class="n">sigma1</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>\
            <span class="n">A2</span><span class="o">=</span><span class="mf">4.43181</span><span class="p">,</span><span class="n">x2</span><span class="o">=</span><span class="mf">0.65</span><span class="p">,</span><span class="n">y2</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span><span class="n">sigma2</span><span class="o">=</span><span class="mf">0.04</span><span class="p">):</span>
	<span class="k">return</span> <span class="n">A1</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">x1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma1</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> \
		<span class="n">A2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="p">((</span><span class="n">x</span><span class="o">-</span><span class="n">x2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span><span class="o">-</span><span class="n">y2</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sigma2</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="n">delta</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">delta</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">CS</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">p</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">clabel</span><span class="p">(</span><span class="n">CS</span><span class="p">,</span> <span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">fig3d</span><span class="p">,</span> <span class="n">ax3d</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">subplot_kw</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;projection&quot;</span><span class="p">:</span> <span class="s2">&quot;3d&quot;</span><span class="p">})</span>
<span class="c1"># Plot the surface.</span>
<span class="n">surf</span> <span class="o">=</span> <span class="n">ax3d</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="o">.</span><span class="n">coolwarm</span><span class="p">,</span>
                       <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">antialiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax3d</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">ax3d</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$x$&#39;</span><span class="p">)</span>
<span class="n">ax3d</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">ax3d</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>
<span class="n">ax3d</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p(x,y)$&#39;</span><span class="p">);</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.integrate</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">integrate</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">pdfy</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="k">for</span> <span class="n">iy</span><span class="p">,</span><span class="n">yi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
	<span class="n">I</span> <span class="o">=</span> <span class="n">integrate</span><span class="o">.</span><span class="n">quad</span><span class="p">(</span><span class="n">pdf</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">yi</span><span class="p">))</span>
	<span class="n">pdfy</span><span class="p">[</span><span class="n">iy</span><span class="p">]</span> <span class="o">=</span> <span class="n">I</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">fig_pdfy</span><span class="p">,</span> <span class="n">axy</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">axy</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">pdfy</span><span class="p">)</span>
<span class="n">axy</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$y$&#39;</span><span class="p">)</span>
<span class="n">axy</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p(y)$&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ignoring fixed x limits to fulfill fixed data aspect with adjustable data limits.
</pre></div>
</div>
<img alt="../../_images/99ba6d651e066ad32cfb728e36f7163043f73b7f7c6fe9c8c5d4efb05309981b.png" src="../../_images/99ba6d651e066ad32cfb728e36f7163043f73b7f7c6fe9c8c5d4efb05309981b.png" />
<img alt="../../_images/fc1161c9baf1bc80aa56e9f92cc2d170ef56678cffbd13a17023869479b60a3e.png" src="../../_images/fc1161c9baf1bc80aa56e9f92cc2d170ef56678cffbd13a17023869479b60a3e.png" />
<img alt="../../_images/87fc75c7d9762b43f121a12833ec6a537ce35955dbce0f00a39f701c78a65485.png" src="../../_images/87fc75c7d9762b43f121a12833ec6a537ce35955dbce0f00a39f701c78a65485.png" />
</div>
</details>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./LearningFromData-content/Reference"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../Backmatter/JB_tests.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">34. </span>Guide to Jupyter Book markdown</p>
      </div>
    </a>
    <a class="right-next"
       href="../ModelingOptimization/GradientDescent.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">36. </span>Gradient-descent optimization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#notation">35.1. Notation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#important-definitions">35.2. Important definitions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-probability-measure">The probability measure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-variables-probability-distribution-and-density">Random variables: probability distribution and density</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expectation-values-and-moments">Expectation values and moments</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#central-moments-variance-and-covariance">Central moments: Variance and Covariance</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#important-distributions">35.3. Important distributions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-uniform-distribution">The uniform distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-distribution">Gaussian distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-gaussian-distribution">Multivariate Gaussian distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-introduction-to-scipy-stats">35.4. Quick introduction to  <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-example">Code example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pseudo-random-number-generator">(Pseudo) random number generator</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#point-estimates-and-credible-regions">35.5. Point estimates and credible regions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mean-median-mode">Mean, median, mode</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#credible-regions">Credible regions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-probability">35.6. Types of probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">35.7. Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions">35.8. Solutions</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Christian ForssÃ©n, Dick Furnstahl, and Daniel Phillips
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>