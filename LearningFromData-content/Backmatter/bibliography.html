
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>33. Bibliography &#8212; Combined Learning from Data materials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../_static/coloredpages.css?v=0a037ad7" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css?v=6bd7df4c" />
    <link rel="stylesheet" type="text/css" href="../../_static/myadmonitions.css?v=89ac28d1" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'LearningFromData-content/Backmatter/bibliography';</script>
    <script src="../../_static/custom.js?v=33f35b7a"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="34. Guide to Jupyter Book markdown" href="JB_tests.html" />
    <link rel="prev" title="32. Quantum Bayesianism (QBism)" href="../OtherTopics/qbism.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../Intro/About.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo-copilot.png" class="logo__image only-light" alt="Combined Learning from Data materials - Home"/>
    <script>document.write(`<img src="../../_static/logo-copilot.png" class="logo__image only-dark" alt="Combined Learning from Data materials - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../Intro/About.html">
                    Learning from data for physicists:
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Intro/Invitation.html">1. Invitation to inductive inference</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Intro/Introduction.html">2. Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction/sec-01-physicist-s-perspective.html">2.1. Physicistâ€™s perspective</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction/sec-02-bayesian-workflow.html">2.2. Bayesian workflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction/sec-03-machine-learning.html">2.3. Machine learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction/sec-04-virtues.html">2.4. Virtues</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part I: Bayesian methods for scientific modeling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/RootBayesianBasics.html">3. Overview of Part I</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs.html">4. Inference and PDFs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-01-statements.html">4.1. Statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-02-manipulating-probabilities-bayesian-rules-of-probability-as.html">4.2. Manipulating probabilities: Bayesian rules of probability as principles of logic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-03-probability-density-functions.html">4.3. Probability density functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Inferenceandpdfs/sec-04-summary.html">4.4. Looking ahead</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/MoreBayesTheorem.html">4.5. Review of Bayesâ€™ theorem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/DataModelsPredictions.html">4.6. Data, models, and predictions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Bayesian_epistemology.html">4.7. *Aside: Bayesian epistemology</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Posteriors.html">5. Bayesian posteriors</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Exploring_pdfs.html">5.1. ðŸ“¥ Exploring PDFs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Exploring_pdfs_followups.html">Follow-ups to Exploring PDFs</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Visualizing_correlated_gaussians.html">5.2. ðŸ“¥ Visualizing correlated Gaussian distributions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Gaussians.html">5.3. Gaussians: A couple of frequentist connections</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/visualization_of_CLT.html">ðŸ“¥ Visualization of the Central Limit Theorem</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/Interpreting2Dposteriors.html">5.4. Interpreting 2D posteriors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/chi_squared_tests.html">5.5. ðŸ“¥ Demonstration: Sum of normal variables squared</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing.html">6. Updating via Bayes' rule</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-01-coin-tossing-frequentists-and-bayesaians.html">6.1. Coin tossing: Frequentists and Bayesaians</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-02-when-do-priors-matter-when-don-t-they-matter.html">6.2. When do priors matter? When donâ€™t they matter?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-03-computing-the-posterior-analytically.html">6.3. Computing the posterior analytically</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-04-degree-of-belief-credibility-intervals-vs-frequentist-1-sigm.html">6.4. Degree of belief/credibility intervals vs frequentist 1-sigma intervals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/CoinTossing/sec-05-take-aways-and-follow-up-questions-from-coin-flipping.html">6.5. Take-aways and follow-up questions from coin flipping</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/demo-BayesianBasics.html">6.6. ðŸ“¥ Demonstration:  Bayesian Coin Tossing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/Bayesian_updating_coinflip_interactive.html">6.7. ðŸ“¥ Demonstration: Coin tossing (with widget)</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/UsingBayes.html">7. Bayes in practice</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/BayesianAdvantages.html">7.1. Advantages of the Bayesian approach</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianWorkflow/BayesianWorkflow.html">7.2. Bayesian research workflow</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianLinearRegression/BayesianLinearRegression_rjf.html">7.3. Bayesian Linear Regression (BLR)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../ModelingOptimization/demo-ModelValidation.html">ðŸ“¥ Demonstration: Linear Regression and Model Validation</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation.html">8. Error propagation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation/sec-01-error-propagation-i-nuisance-parameters-and-marginalization.html">8.1. Error propagation (I): Nuisance parameters and marginalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation/sec-02-error-propagation-ii-changing-variables.html">8.2. Error propagation (II): Changing variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation/sec-03-error-propagation-iii-a-useful-approximation.html">8.3. Error propagation (III): A useful approximation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/ErrorPropagation/sec-04-solutions.html">8.4. Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/Exercises_parameter_estimation.html">9. Exercises for Part I</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/exercise_sum_product_rule.html">9.1. Exercise: Checking the sum and product rules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianBasics/exercise_medical_example_by_Bayes.html">9.2. Exercise: Standard medical example using Bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/parameter_estimation_Gaussian_noise.html">9.3. ðŸ“¥ Parameter estimation I: Gaussian mean and variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/radioactive_lighthouse_exercise.html">9.4. ðŸ“¥ Radioactive lighthouse problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/amplitude_in_presence_of_background.html">9.5. ðŸ“¥ Amplitude of a signal in the presence of background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_I.html">9.6. ðŸ“¥ Parameter estimation example: fitting a straight line</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/parameter_estimation_fitting_straight_line_II.html">9.7. ðŸ“¥ Parameter estimation example: fitting a straight line II</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part II: Advanced Bayesian methods</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../BayesianStatistics/RootAdvancedMethods.html">10. Overview of Part II</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../OtherTopics/DiscrepancyModels.html">11. Discrepancy Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/DiscrepancyModels/sec-01-koh-and-boh-discrepancy-models.html">11.1. KOH and BOH discrepancy models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/DiscrepancyModels/sec-02-framework.html">11.2. Framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/DiscrepancyModels/sec-03-the-ball-drop-model.html">11.3. The ball-drop model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/MD_balldrop_v1.html">11.4. ðŸ“¥ Ball-drop experiment notebook</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/Assigning.html">12. Assigning probabilities</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/IgnorancePDF.html">12.1. Assigning probabilities (I): Indifferences and translation groups</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/demo-straight_lines.html">Alternative notebook with MCMC sampling</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/MaxEnt2.html">12.2. Assigning probabilities (II): The principle of maximum entropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/AssigningProbabilities/MaxEnt_Function_Reconstruction.html">12.3. ðŸ“¥ Maximum Entropy for reconstructing a function from its moments</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../BayesianStatistics/BayesianParameterEstimation/dealing_with_outliers.html">13. ðŸ“¥ Dealing with outliers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../BayesianStatistics/ComputationalBayes/BayesLinear.html">14. Bayes goes linear: History matching</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../BayesianStatistics/Multimodel_inference.html">15. Multi-model inference with Bayes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../BayesianStatistics/ModelSelection/ModelSelection.html">15.1. Model Selection</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/ModelSelection/BUQ/Evidence_for_model_EFT_coefficients.html">Evidence calculation for EFT expansions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/ModelSelection/BUQ/two_model_evidence.html">Follow-up to EFT evidence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/ModelSelection/BUQ/computing_evidence.html">Computing the evidence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../BayesianStatistics/ModelSelection/BUQ/MCMC-parallel-tempering_ptemcee_vs_zeus.html">Demo: Multimodal distributions with two samplers</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/ModelMixing/model_mixing.html">15.2. Model averaging and mixing </a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part III: MCMC sampling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../StochasticProcesses/RootMCMC.html">16. Overview of Part III</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../StochasticProcesses/StochasticProcesses.html">17. Stochastic processes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/Metropolis_Poisson_example.html">17.7. Metropolis-Hasting MCMC sampling of a Poisson distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/demo-MCMC.html">17.8. Demonstration: Metropolis-Hasting MCMC sampling of a Poisson distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/Recap_BUQ.html">17.9. Recap of Poisson and more about MCMC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/parameter_estimation_Gaussian_noise-2.html">17.10. Parameter estimation example: Gaussian noise and averages II</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/MCMC-random-walk-and-sampling.html">17.11. Exercise: Random walk</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../StochasticProcesses/MCMC_overview.html">18. Overview of Markov Chain Monte Carlo</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/MarkovChains.html">18.1. Markov chains</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/MCMC.html">18.2. Markov chain Monte Carlo sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/MCMC_intro_BUQ.html">18.3. Alternative MCMC introduction (Gregory)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/Assignment_extending_radioactive_lighthouse.html">18.4. Assignment: 2D radioactive lighthouse location using MCMC</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../StochasticProcesses/Advanced_MCMC.html">19. Advanced MCMC</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/ComputationalBayes/AdvancedMCMC.html">19.1. Advanced Markov chain Monte Carlo sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/MCMC-diagnostics.html">19.2. Overview: MCMC Diagnostics</a></li>

<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ/intuition_sampling.html">19.4. Intuition on sampling and best practices</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../StochasticProcesses/Other_samplers.html">20. HMC and other samplers</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../StochasticProcesses/BUQ2/HMC_intro_BUQ.html">20.1. Hamiltonian Monte Carlo (HMC) overview and visualization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../StochasticProcesses/BUQ2/Liouville_theorem_visualization.html">Liouville Theorem Visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../StochasticProcesses/BUQ2/Orbital_eqs_with_different_algorithms.html">Solving orbital equations with different algorithms</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/zeus.html">20.2. The Zeus Ensemble Slice Sampler</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../StochasticProcesses/BUQ2/PyMC_intro_updated.html">20.3. PyMC Introduction</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../StochasticProcesses/OverviewIntroPyMC.html">Overview of Intro to PyMC notebook</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../StochasticProcesses/BUQ2/parameter_estimation_Gaussian_noise_compare_samplers.html">20.4. Comparing samplers for a simple problem</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part IV: Machine learning: A Bayesian perspective</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../MachineLearning/RootML.html">21. Overview of Part IV</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/GP/RootGP.html">22. Overview of Gaussian processes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../MachineLearning/GP/GaussianProcesses.html">22.4. Introduction to Gaussian processes</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/CF/demo-GaussianProcesses.html">ðŸ“¥ demo-GaussianProcesses notebook</a></li>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/lecture_20.html">GP recap; GP applications; (old lecture 20)</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../MachineLearning/GP/Sklearn_demos.html">22.5. scikit-learn demo notebooks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/plot_gpr_noisy_targets.html">ðŸ“¥ One-dimension regression example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/plot_gpr_prior_posterior.html">ðŸ“¥ Prior and posterior with different kernels</a></li>
</ul>
</details></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../MachineLearning/GP/GPy_demos.html">22.6. GPy demo notebooks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/demo-GaussianProcesses.html">Gaussian processes demonstration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/CF/exercise_GP_GPy.html">Exercise: Gaussian processes using <code class="docutils literal notranslate"><span class="pre">GPy</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../MachineLearning/GP/BUQ/Gaussian_processes_exercises.html">Exercise: Gaussian Process models with GPy</a></li>
</ul>
</details></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/LogReg/LogReg.html">23. Logistic Regression</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/MachineLearningExamples.html">23.5. Machine Learning: First Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/NeuralNet/exercises_LogReg_NeuralNet.html">23.6. Exercise: Logistic Regression and neural networks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/ANN/MachineLearning.html">24. Machine learning: Overview and notation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/NeuralNet.html">24.5. Artifical neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/NeuralNet/demo-NeuralNet.html">24.6. Demonstration: Neural network classifier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/Neural_Network_for_simple_function_in_PyTorch.html">24.7. ðŸ“¥ ANN from ChatGPT using PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/ModelValidation.html">24.8. Model validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/DataBiasFairness.html">24.9. Data bias and fairness in machine learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/ANN/NeuralNet/NeuralNetBackProp.html">24.10. *Neural networks: Backpropagation</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../OtherTopics/ANNFT.html">25. ANNs in the large-width limit (ANNFT)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/random_initialized_ANN_vs_width.html">25.3. ðŸ“¥ Distributions of Randomly-Initialized ANNs</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/BNN/bnn.html">26. Bayesian neural nets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/BNN/demo-bnn.html">26.4. Demonstration: Variational Inference and Bayesian Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/BNN/exercises_BNN.html">26.5. Exercise: Bayesian neural networks</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../MachineLearning/CNN/cnn.html">27. *Convolutional neural nets</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../MachineLearning/CNN/demo-cnn.html">27.6. Demonstration: Image recognition with Convolutional Neural Networks</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part V: Other topics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../OtherTopics/RootOtherTopics.html">28. Overview of Part V </a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../OtherTopics/Emulators.html">29. Emulators</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/ComputationalBayes/BayesFast.html">29.1. Bayes goes fast: Emulators (from CF)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../BayesianStatistics/ComputationalBayes/extra_RBM_emulators.html">29.2. RBM emulators (BUQ)</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../OtherTopics/Student_t_distribution_from_Gaussians.html">30. ðŸ“¥ Student t distribution from Gaussians</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../OtherTopics/SVD.html">31. PCA, SVD, and all that</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../OtherTopics/linear_algebra_games_including_SVD.html">31.5. ðŸ“¥ demo-SVD notebook</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../OtherTopics/qbism.html">32. QBism: Bayesian quantum mechanics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Backmatter</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">33. Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="JB_tests.html">34. Guide to Jupyter Book markdown</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix A: Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Reference/Statistics.html">35. Statistics concepts and notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ModelingOptimization/GradientDescent.html">36. Gradient-descent optimization</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix B: Scientific modeling</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../ModelingOptimization/RootScientificModeling.html">37. Overview of scientific modeling material</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ModelingOptimization/OverviewModeling.html">38. Overview of modeling</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-01-notation.html">38.1. Notation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-02-models-in-science.html">38.2. Models in science</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-03-parametric-versus-non-parametric-models.html">38.3. Parametric versus non-parametric models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-04-linear-versus-non-linear-models.html">38.4. Linear versus non-linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-05-regression-analysis-optimization-versus-inference.html">38.5. Regression analysis: optimization versus inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-06-exercises.html">38.6. Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/OverviewModeling/sec-07-solutions.html">38.7. Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ModelingOptimization/LinearModels.html">39. Linear models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-01-definition-of-linear-models.html">39.1. Definition of linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-02-regression-analysis-with-linear-models.html">39.2. Regression analysis with linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-03-ordinary-linear-regression-warmup.html">39.3. Ordinary linear regression: warmup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-04-ordinary-linear-regression-in-practice.html">39.4. Ordinary linear regression in practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/LinearModels/sec-05-solutions.html">39.5. Solutions</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../ModelingOptimization/MathematicalOptimization.html">40. Mathematical optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/MathematicalOptimization/sec-01-gradient-descent-optimization.html">40.1. Gradient-descent optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/MathematicalOptimization/sec-02-batch-stochastic-and-mini-batch-gradient-descent.html">40.2. Batch, stochastic and mini-batch gradient descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../ModelingOptimization/MathematicalOptimization/sec-03-adaptive-gradient-descent-algorithms.html">40.3. Adaptive gradient descent algorithms</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendix C: Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Setup/RootGettingStarted.html">41. Overview of Getting started material</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Setup/exercise_Intro_01_Jupyter_Python.html">42. ðŸ“¥ Exercise: Jupyter notebooks and Python</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Setup/more_python_and_jupyter.html">43. More about Python and Jupyter notebooks</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Setup/exercise_Intro_02_Jupyter_Python.html">43.4. ðŸ“¥ Python lists and iterations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Setup/exercise_Intro_03_Numpy.html">43.5. ðŸ“¥ Linear algebra operations with NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Setup/demo-Intro.html">43.6. ðŸ“¥ Reading data and fitting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Setup/Simple_widgets_v1.html">43.7. ðŸ“¥ Making a simple widget-based UI</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Setup/setting_up.html">44. Setting up for using this Jupyter Book</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Setup/installing_anaconda.html">44.1. Using Anaconda</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Setup/using_github.html">44.2. Using GitHub</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">TALENT mini-projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/RootMiniProjects.html">Overview of mini-projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/mini-project_I_toy_model_of_EFT.html">ðŸ“¥ MP I: Parameter estimation for a toy model of an EFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/model-selection_mini-project-IIa.html">ðŸ“¥ MP IIa: Model selection basics</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Mini-projects/model-selection_mini-project-IIb_How_many_lines_ptemcee.html">ðŸ“¥ MP IIb: How many lines?</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../Mini-projects/Mini-project_IIb_overview.html">Overview of Mini-project IIb: How many lines?</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/mini-project_IIIa_bayesian_optimization.html">ðŸ“¥ MP IIIa: Bayesian optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Mini-projects/mini-project_IIIb_Bayesian_neural_networks_from_demo.html">ðŸ“¥ MP IIIb: Bayesian Neural Networks</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/NuclearTalent/LFD_for_Physicists" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/NuclearTalent/LFD_for_Physicists/issues/new?title=Issue%20on%20page%20%2FLearningFromData-content/Backmatter/bibliography.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/LearningFromData-content/Backmatter/bibliography.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bibliography</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="bibliography">
<h1><span class="section-number">33. </span>Bibliography<a class="headerlink" href="#bibliography" title="Link to this heading">#</a></h1>
<p>This is a partial list of good references.</p>
<div class="docutils container" id="id1">
<div role="list" class="citation-list">
<div class="citation" id="id44" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>BS06<span class="fn-bracket">]</span></span>
<p>J.M. Bernardo and A.F.M. Smith. <em>Bayesian Theory</em>. Wiley Series in Probability and Statistics. John Wiley &amp; Sons Canada, Limited, 2006. ISBN 9780470028735.</p>
</div>
<div class="citation" id="id35" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>BCKW15<span class="fn-bracket">]</span></span>
<p>Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural networks. 2015. <a class="reference external" href="https://doi.org/10.48550/ARXIV.1505.05424">doi:10.48550/ARXIV.1505.05424</a>.</p>
</div>
<div class="citation" id="id52" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>BGJM11<span class="fn-bracket">]</span></span>
<p>S.Â Brooks, A.Â Gelman, G.Â Jones, and X.L. Meng. <em>Handbook of Markov Chain Monte Carlo</em>. Chapman &amp; Hall/CRC Handbooks of Modern Statistical Methods. CRC Press, 2011. ISBN 9781420079425. URL: <a class="reference external" href="https://books.google.se/books?id=qfRsAIKZ4rIC">https://books.google.se/books?id=qfRsAIKZ4rIC</a>.</p>
</div>
<div class="citation" id="id3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Cox61<span class="fn-bracket">]</span></span>
<p>RichardÂ Threlkeld Cox. <em>The Algebra of Probable Inference</em>. Johns Hopkins University Press, 1961.</p>
</div>
<div class="citation" id="id28" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Cyb89<span class="fn-bracket">]</span></span>
<p>GÂ Cybenko. Approximation by superpositions of a sigmoidal function. <em>Math. Control Signal Systems</em>, 2:303â€“314, 1989. <a class="reference external" href="https://doi.org/10.1007/BF02551274">doi:10.1007/BF02551274</a>.</p>
</div>
<div class="citation" id="id50" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DMF+22<span class="fn-bracket">]</span></span>
<p>C.Â Drischler, J.Â A. Melendez, R.Â J. Furnstahl, A.Â J. Garcia, and Xilin Zhang. BUQEYE guide to projection-based emulators in nuclear physics. <em>Front. in Phys.</em>, 10:1092931, 2022. <a class="reference external" href="https://arxiv.org/abs/2212.04912">arXiv:2212.04912</a>, <a class="reference external" href="https://doi.org/10.3389/fphy.2022.1092931">doi:10.3389/fphy.2022.1092931</a>.</p>
</div>
<div class="citation" id="id51" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DKPR87<span class="fn-bracket">]</span></span>
<p>S.Â Duane, A.Â D. Kennedy, B.Â J. Pendleton, and D.Â Roweth. Hybrid Monte Carlo. <em>Phys. Lett. B</em>, 195:216â€“222, 1987. <a class="reference external" href="https://doi.org/10.1016/0370-2693(87)91197-X">doi:10.1016/0370-2693(87)91197-X</a>.</p>
</div>
<div class="citation" id="id55" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DHS11<span class="fn-bracket">]</span></span>
<p>John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. <em>Journal of Machine Learning Research</em>, 12(61):2121â€“2159, 2011. URL: <a class="reference external" href="http://jmlr.org/papers/v12/duchi11a.html">http://jmlr.org/papers/v12/duchi11a.html</a>.</p>
</div>
<div class="citation" id="id25" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>FHB09<span class="fn-bracket">]</span></span>
<p>FÂ Feroz, MÂ P Hobson, and MÂ Bridges. MultiNest: an efficient and robust Bayesian inference tool for cosmology and particle physics. <em>Monthly Notices of the Royal Astronomical Society</em>, 398(4):1601â€“1614, September 2009. <a class="reference external" href="https://doi.org/10.1111/j.1365-2966.2009.14548.x">doi:10.1111/j.1365-2966.2009.14548.x</a>.</p>
</div>
<div class="citation" id="id23" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>FMHLG13<span class="fn-bracket">]</span></span>
<p>Daniel Foreman-Mackey, DavidÂ W. Hogg, Dustin Lang, and Jonathan Goodman. Emcee: the mcmc hammer. <em>Publications of the Astronomical Society of the Pacific</em>, 125(925):306â€“312, Mar 2013. <a class="reference external" href="https://doi.org/10.1086/670067">doi:10.1086/670067</a>.</p>
</div>
<div class="citation" id="id47" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>FHI+18<span class="fn-bracket">]</span></span>
<p>Dillon Frame, Rongzheng He, Ilse Ipsen, Daniel Lee, Dean Lee, and Ermal Rrapaj. Eigenvector continuation with subspace learning. <em>Phys. Rev. Lett.</em>, 121(3):032501, 2018. <a class="reference external" href="https://arxiv.org/abs/1711.07090">arXiv:1711.07090</a>, <a class="reference external" href="https://doi.org/10.1103/PhysRevLett.121.032501">doi:10.1103/PhysRevLett.121.032501</a>.</p>
</div>
<div class="citation" id="id2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GCS+13<span class="fn-bracket">]</span></span>
<p>A.Â Gelman, J.B. Carlin, H.S. Stern, D.B. Dunson, A.Â Vehtari, and D.B. Rubin. <em>Bayesian Data Analysis, Third Edition</em>. Chapman &amp; Hall/CRC Texts in Statistical Science. Taylor &amp; Francis, 2013. URL: <a class="reference external" href="http://www.stat.columbia.edu/~gelman/book/BDA3.pdf">http://www.stat.columbia.edu/~gelman/book/BDA3.pdf</a>.</p>
</div>
<div class="citation" id="id46" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GR92<span class="fn-bracket">]</span></span>
<p>Andrew Gelman and DonaldÂ B. Rubin. Inference from iterative simulation using multiple sequences. <em>Statistical Science</em>, 7(4):457â€“472, 1992. URL: <a class="reference external" href="http://www.jstor.org/stable/2246093">http://www.jstor.org/stable/2246093</a>.</p>
</div>
<div class="citation" id="id6" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GW07<span class="fn-bracket">]</span></span>
<p>M.Â Goldstein and D.Â Wooff. <em>Bayes Linear Statistics: Theory and Methods</em>. Wiley Series in Probability and Statistics. Wiley, 2007. ISBN 9780470015629.</p>
</div>
<div class="citation" id="id24" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>GW10<span class="fn-bracket">]</span></span>
<p>Jonathan Goodman and Jonathan Weare. Ensemble samplers with affine invariance. <em>Comm. App. Math. and Comp. Sci.</em>, 5(1):65â€“80, 2010. <a class="reference external" href="https://doi.org/10.2140/camcos.2010.5.65">doi:10.2140/camcos.2010.5.65</a>.</p>
</div>
<div class="citation" id="id22" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Gre05<span class="fn-bracket">]</span></span>
<p>Phil Gregory. <em>Bayesian Logical Data Analysis for the Physical Sciences: A Comparative Approach with MathematicaÂ® Support</em>. Cambridge University Press, 2005. <a class="reference external" href="https://doi.org/10.1017/CBO9780511791277">doi:10.1017/CBO9780511791277</a>.</p>
</div>
<div class="citation" id="id12" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Geron17<span class="fn-bracket">]</span></span>
<p>A.Â GÃ©ron. <em>Hands-on Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems</em>. O'Reilly Media, 2017. ISBN 9781491962299. URL: <a class="reference external" href="https://books.google.se/books?id=I6qkDAEACAAJ">https://books.google.se/books?id=I6qkDAEACAAJ</a>.</p>
</div>
<div class="citation" id="id19" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Hal21<span class="fn-bracket">]</span></span>
<p>James Halverson. Building Quantum Field Theories Out of Neurons. 12 2021. <a class="reference external" href="https://arxiv.org/abs/2112.04527">arXiv:2112.04527</a>.</p>
</div>
<div class="citation" id="id18" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HMS21<span class="fn-bracket">]</span></span>
<p>James Halverson, Anindita Maiti, and Keegan Stoner. Neural Networks and Quantum Field Theory. <em>Mach. Learn. Sci. Tech.</em>, 2(3):035002, 2021. <a class="reference external" href="https://arxiv.org/abs/2008.08601">arXiv:2008.08601</a>, <a class="reference external" href="https://doi.org/10.1088/2632-2153/abeca3">doi:10.1088/2632-2153/abeca3</a>.</p>
</div>
<div class="citation" id="id13" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HTF09<span class="fn-bracket">]</span></span>
<p>T.Â Hastie, R.Â Tibshiranie, and J.Â Friedman. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer, 2009. ISBN 978-0-387-84858-7. URL: <a class="reference external" href="https://link.springer.com/book/10.1007/978-0-387-84858-7">https://link.springer.com/book/10.1007/978-0-387-84858-7</a>.</p>
</div>
<div class="citation" id="id54" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HG+14<span class="fn-bracket">]</span></span>
<p>MatthewÂ D Hoffman, Andrew Gelman, and others. The no-u-turn sampler: adaptively setting path lengths in hamiltonian monte carlo. <em>J. Mach. Learn. Res.</em>, 15(1):1593â€“1623, 2014.</p>
</div>
<div class="citation" id="id40" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>H+22<span class="fn-bracket">]</span></span>
<p>Baishan Hu and others. Ab initio predictions link the neutron skin of $^208$Pb to nuclear forces. <em>Nature Phys.</em>, 18(10):1196â€“1200, 2022. <a class="reference external" href="https://arxiv.org/abs/2112.01125">arXiv:2112.01125</a>, <a class="reference external" href="https://doi.org/10.1038/s41567-022-01715-8">doi:10.1038/s41567-022-01715-8</a>.</p>
</div>
<div class="citation" id="id8" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Jay88<span class="fn-bracket">]</span></span>
<p>E.Â T. Jaynes. <em>How Does the Brain Do Plausible Reasoning?</em>, pages 1â€“24. Springer Netherlands, Dordrecht, 1988. <a class="reference external" href="https://doi.org/10.1007/978-94-009-3049-0_1">doi:10.1007/978-94-009-3049-0_1</a>.</p>
</div>
<div class="citation" id="id5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Jay03<span class="fn-bracket">]</span></span>
<p>E.Â T. Jaynes. <em>Probability Theory: The Logic of Science</em>. Cambridge University Press, 2003. <a class="reference external" href="https://doi.org/10.1017/CBO9780511790423">doi:10.1017/CBO9780511790423</a>.</p>
</div>
<div class="citation" id="id42" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>JForssen22<span class="fn-bracket">]</span></span>
<p>Weiguang Jiang and Christian ForssÃ©n. Bayesian probability updates using sampling/importance resampling: Applications in nuclear theory. <em>Front. in Phys.</em>, 10:1058809, 2022. <a class="reference external" href="https://arxiv.org/abs/2210.02507">arXiv:2210.02507</a>, <a class="reference external" href="https://doi.org/10.3389/fphy.2022.1058809">doi:10.3389/fphy.2022.1058809</a>.</p>
</div>
<div class="citation" id="id34" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>KRGB15<span class="fn-bracket">]</span></span>
<p>Alp Kucukelbir, Rajesh Ranganath, Andrew Gelman, and DavidÂ M. Blei. Automatic variational inference in stan. 2015. <a class="reference external" href="https://doi.org/10.48550/ARXIV.1506.03431">doi:10.48550/ARXIV.1506.03431</a>.</p>
</div>
<div class="citation" id="id11" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LWahlstromLSchon21<span class="fn-bracket">]</span></span>
<p>A.Â Lindholm, N.Â WahlstrÃ¶m, F.Â Lindsten, and T.Â B. SchÃ¶n. <em>Machine Learning: A First Course for Engineers and Scientists</em>. Cambridge University Press, 2021. ISBN 9781108843607. URL: <a class="reference external" href="http://smlbook.org/book/sml-book-draft-latest.pdf">http://smlbook.org/book/sml-book-draft-latest.pdf</a>.</p>
</div>
<div class="citation" id="id33" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Mac03<span class="fn-bracket">]</span></span>
<p>D.J.C. MacKay. <em>Information Theory, Inference and Learning Algorithms</em>. Cambridge University Press, 2003. ISBN 9780521642989. URL: <a class="reference external" href="http://www.inference.org.uk/mackay/itila/">http://www.inference.org.uk/mackay/itila/</a>.</p>
</div>
<div class="citation" id="id41" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>May22<span class="fn-bracket">]</span></span>
<p>Eleanor May. Bayesian history matching of chiral effective field theory in the two-nucleon sector. Master's thesis, Chalmers, 2022.</p>
</div>
<div class="citation" id="id16" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MBW+19<span class="fn-bracket">]</span></span>
<p>Pankaj Mehta, Marin Bukov, Ching-Hao Wang, AlexandreÂ G.R. Day, Clint Richardson, CharlesÂ K. Fisher, and DavidÂ J. Schwab. A high-bias, low-variance introduction to machine learning for physicists. <em>Phys. Rep.</em>, 810:1â€“124, may 2019. <a class="reference external" href="https://doi.org/10.1016/j.physrep.2019.03.001">doi:10.1016/j.physrep.2019.03.001</a>.</p>
</div>
<div class="citation" id="id48" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MDF+22<span class="fn-bracket">]</span></span>
<p>J.Â A. Melendez, C.Â Drischler, R.Â J. Furnstahl, A.Â J. Garcia, and Xilin Zhang. Model reduction methods for nuclear emulators. <em>J. Phys. G</em>, 49(10):102001, 2022. <a class="reference external" href="https://arxiv.org/abs/2203.05528">arXiv:2203.05528</a>, <a class="reference external" href="https://doi.org/10.1088/1361-6471/ac83dd">doi:10.1088/1361-6471/ac83dd</a>.</p>
</div>
<div class="citation" id="id31" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Pol54a<span class="fn-bracket">]</span></span>
<p>George Polya. <em>Mathematics and Plausible Reasoning, Volume 1: Induction and Analogy in Mathematics</em>. Princeton University Press, 1954.</p>
</div>
<div class="citation" id="id32" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Pol54b<span class="fn-bracket">]</span></span>
<p>George Polya. <em>Mathematics and Plausible Reasoning, Volume 2: Patterns of Plausible Inference</em>. Princeton University Press, 1954.</p>
</div>
<div class="citation" id="id36" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Puk94<span class="fn-bracket">]</span></span>
<p>Friedrich Pukelsheim. The three sigma rule. <em>The American Statistician</em>, 48(2):88â€“91, 1994. URL: <a class="reference external" href="http://www.jstor.org/stable/2684253">http://www.jstor.org/stable/2684253</a>.</p>
</div>
<div class="citation" id="id49" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>QMN15<span class="fn-bracket">]</span></span>
<p>Alfio Quarteroni, Andrea Manzoni, and Federico Negri. <em>Reduced Basis Methods for Partial Differential Equations</em>. Springer International Publishing, 2015. ISBN 9783319154305. <a class="reference external" href="https://doi.org/10.1007/978-3-319-15431-2">doi:10.1007/978-3-319-15431-2</a>.</p>
</div>
<div class="citation" id="id27" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>RW05<span class="fn-bracket">]</span></span>
<p>CarlÂ Edward Rasmussen and Christopher K.Â I. Williams. <em>Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)</em>. The MIT Press, 2005. ISBN 026218253X.</p>
</div>
<div class="citation" id="id20" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Rob21<span class="fn-bracket">]</span></span>
<p>DanielÂ A. Roberts. Why is AI hard and Physics simple? 3 2021. <a class="reference external" href="https://arxiv.org/abs/2104.00008">arXiv:2104.00008</a>.</p>
</div>
<div class="citation" id="id17" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>RYH22<span class="fn-bracket">]</span></span>
<p>DanielÂ A. Roberts, Sho Yaida, and Boris Hanin. <em>The Principles of Deep Learning Theory</em>. Cambridge University Press, 5 2022. ISBN 978-1-00-902340-5. <a class="reference external" href="https://arxiv.org/abs/2106.10165">arXiv:2106.10165</a>, <a class="reference external" href="https://doi.org/10.1017/9781009023405">doi:10.1017/9781009023405</a>.</p>
</div>
<div class="citation" id="id45" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Rub88<span class="fn-bracket">]</span></span>
<p>DonaldÂ B Rubin. Using the sir algorithm to simulate posterior distributions. <em>Bayesian statistics</em>, 3:395â€“402, 1988.</p>
</div>
<div class="citation" id="id7" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SS06<span class="fn-bracket">]</span></span>
<p>D.Â S. Sivia and J.Â Skilling. <em>Data Analysis - A Bayesian Tutorial</em>. Oxford Science Publications. Oxford University Press, 2nd edition, 2006.</p>
</div>
<div class="citation" id="id43" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SG92<span class="fn-bracket">]</span></span>
<p>A.Â F.Â M. Smith and A.Â E. Gelfand. Bayesian statistics without tears: a sampling-resampling perspective. <em>Am. Stat.</em>, 46(2):84â€“88, May 1992.</p>
</div>
<div class="citation" id="id10" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Sum21<span class="fn-bracket">]</span></span>
<p>D.Â Sumpter. <em>Ethics in Machine Learning</em>, pages 309â€“326. Cambridge University Press, 2021.</p>
</div>
<div class="citation" id="id53" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SEkstromForssen22<span class="fn-bracket">]</span></span>
<p>Isak Svensson, Andreas EkstrÃ¶m, and Christian ForssÃ©n. Bayesian parameter estimation in chiral effective field theory using the Hamiltonian Monte Carlo method. <em>Phys. Rev. C</em>, 105(1):014004, 2022. <a class="reference external" href="https://arxiv.org/abs/2110.04011">arXiv:2110.04011</a>, <a class="reference external" href="https://doi.org/10.1103/PhysRevC.105.014004">doi:10.1103/PhysRevC.105.014004</a>.</p>
</div>
<div class="citation" id="id21" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Tro08<span class="fn-bracket">]</span></span>
<p>Roberto Trotta. Bayes in the sky: Bayesian inference and model selection in cosmology. <em>Contemp. Phys.</em>, 49:71â€“104, 2008. <a class="reference external" href="https://arxiv.org/abs/0803.4089">arXiv:0803.4089</a>, <a class="reference external" href="https://doi.org/10.1080/00107510802066753">doi:10.1080/00107510802066753</a>.</p>
</div>
<div class="citation" id="id15" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>vW15<span class="fn-bracket">]</span></span>
<p>WesselÂ N. van Wieringen. Lecture notes on ridge regression. 2015. <a class="reference external" href="https://doi.org/10.48550/ARXIV.1509.09169">doi:10.48550/ARXIV.1509.09169</a>.</p>
</div>
<div class="citation" id="id14" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Van16<span class="fn-bracket">]</span></span>
<p>J.Â VanderPlas. <em>Python Data Science Handbook: Essential Tools for Working with Data</em>. O'Reilly Media, 2016. ISBN 9781491912133. URL: <a class="reference external" href="https://books.google.se/books?id=6omNDQAAQBAJ">https://books.google.se/books?id=6omNDQAAQBAJ</a>.</p>
</div>
<div class="citation" id="id38" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>VGB14<span class="fn-bracket">]</span></span>
<p>Ian Vernon, Michael Goldstein, and Richard Bower. Galaxy formation: bayesian history matching for the observable universe. <em>Statist. Sci.</em>, 29(1):81â€“90, 02 2014. <a class="reference external" href="https://doi.org/10.1214/12-STS412">doi:10.1214/12-STS412</a>.</p>
</div>
<div class="citation" id="id37" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>VGB10<span class="fn-bracket">]</span></span>
<p>Ian Vernon, Michael Goldstein, and RichardÂ G. Bower. Galaxy formation: a bayesian uncertainty analysis. <em>Bayesian Anal.</em>, 5(4):619â€“669, 12 2010. <a class="reference external" href="https://doi.org/10.1214/10-BA524">doi:10.1214/10-BA524</a>.</p>
</div>
<div class="citation" id="id39" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>VLG+18<span class="fn-bracket">]</span></span>
<p>Ian Vernon, Junli Liu, Michael Goldstein, James Rowe, Jen Topping, and Keith Lindsey. Bayesian uncertainty analysis for complex systems biology models: emulation, global parameter searches and evaluation of gene functions. <em>BMC Systems Biology</em>, 12:1, 1 2018. <a class="reference external" href="https://doi.org/10.1186/s12918-017-0484-3">doi:10.1186/s12918-017-0484-3</a>.</p>
</div>
<div class="citation" id="id9" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>WAK+17<span class="fn-bracket">]</span></span>
<p>Meng Wang, G.Â Audi, F.Â G. Kondev, W.J. Huang, S.Â Naimi, and Xing Xu. The AME2016 atomic mass evaluation (II). tables, graphs and references. <em>Chinese Phys. C</em>, 41(3):030003, mar 2017. <a class="reference external" href="https://doi.org/10.1088/1674-1137/41/3/030003">doi:10.1088/1674-1137/41/3/030003</a>.</p>
</div>
<div class="citation" id="id57" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>KingmaBa14<span class="fn-bracket">]</span></span>
<p>DiederikÂ P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. <em>arXiv e-prints</em>, pages arXiv:1412.6980, December 2014. <a class="reference external" href="https://arxiv.org/abs/1412.6980">arXiv:1412.6980</a>, <a class="reference external" href="https://doi.org/10.48550/arXiv.1412.6980">doi:10.48550/arXiv.1412.6980</a>.</p>
</div>
<div class="citation" id="id29" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>RumelhartHintonWilliams86<span class="fn-bracket">]</span></span>
<p>DavidÂ E. Rumelhart, GeoffreyÂ E. Hinton, and RonaldÂ J. Williams. Learning representations by back-propagating errors. <em>Nature</em>, 323(6088):533â€“536, October 1986. <a class="reference external" href="https://doi.org/10.1038/323533a0">doi:10.1038/323533a0</a>.</p>
</div>
<div class="citation" id="id58" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>vandSchootDK+21<span class="fn-bracket">]</span></span>
<p>Rens van de Schoot, Sarah Depaoli, Ruth King, Bianca Kramer, Kaspar MÃ¤rtens, MahletÂ G. Tadesse, Marina Vannucci, Andrew Gelman, Duco Veen, Joukje Willemsen, and Christopher Yau. Bayesian statistics and modelling. <em>Nat Rev Methods Primers</em>, 1:1, 2021. <a class="reference external" href="https://doi.org/10.1038/s43586-020-00001-2">doi:10.1038/s43586-020-00001-2</a>.</p>
</div>
<div class="citation" id="id56" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Zeiler12<span class="fn-bracket">]</span></span>
<p>MatthewÂ D. Zeiler. ADADELTA: An Adaptive Learning Rate Method. <em>arXiv e-prints</em>, pages arXiv:1212.5701, December 2012. <a class="reference external" href="https://arxiv.org/abs/1212.5701">arXiv:1212.5701</a>, <a class="reference external" href="https://doi.org/10.48550/arXiv.1212.5701">doi:10.48550/arXiv.1212.5701</a>.</p>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./LearningFromData-content/Backmatter"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../OtherTopics/qbism.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">32. </span>Quantum Bayesianism (QBism)</p>
      </div>
    </a>
    <a class="right-next"
       href="JB_tests.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">34. </span>Guide to Jupyter Book markdown</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Christian ForssÃ©n, Dick Furnstahl, and Daniel Phillips
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2025.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>